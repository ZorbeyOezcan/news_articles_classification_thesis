{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Phase 2: EuroBERT-210M\n",
    "## Eingeengter Suchbereich basierend auf Phase 1\n",
    "\n",
    "Verfeinerte Hyperparameter-Suche basierend auf den Top-5-Trials aus Phase 1.\n",
    "\n",
    "**Phase 1 Ergebnisse (Best F1 Macro CV Mean: 0.8393):**\n",
    "- Learning Rate: 3.7e-5 bis 5e-5 (oberes Ende performt besser)\n",
    "- Scheduler: `linear` dominiert (4/5 Top Trials)\n",
    "- Epochs: 13-15 (mehr Training = besser)\n",
    "- Dropout: 0.26-0.40 (mittlerer Bereich)\n",
    "- Batch Size: 4 dominiert (4/5 Top Trials)\n",
    "\n",
    "**Phase 2 Strategie:**\n",
    "- Eingeengte Suchbereiche um Top-5-Region\n",
    "- `linear` Scheduler und Batch Size 4 fixiert\n",
    "- NaN-Detection fuer sofortiges Pruning instabiler Trials\n",
    "- 20 Trials fuer feinere Suche im engen Raum\n",
    "\n",
    "**Voraussetzung:** GPU-Runtime (L4 empfohlen), `HF_TOKEN` in Colab Secrets hinterlegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETUP ===\n",
    "import os, sys\n",
    "\n",
    "# Repo klonen / aktualisieren\n",
    "REPO = \"/content/news_articles_classification_thesis\"\n",
    "if not os.path.exists(REPO):\n",
    "    !git clone https://github.com/ZorbeyOezcan/news_articles_classification_thesis.git {REPO}\n",
    "else:\n",
    "    !cd {REPO} && git pull -q\n",
    "\n",
    "# Dependencies (+ optuna, plotly, kaleido fuer HPT)\n",
    "!pip install -q transformers[sentencepiece] datasets huggingface_hub \\\n",
    "    scikit-learn matplotlib seaborn tqdm pandas accelerate evaluate \\\n",
    "    optuna plotly kaleido\n",
    "\n",
    "# Google Drive mounten (persistente Reports + Optuna DB)\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=False)\n",
    "\n",
    "# pipeline_utils importierbar machen\n",
    "PIPELINE_DIR = f\"{REPO}/Python/classification_pipeline\"\n",
    "if PIPELINE_DIR not in sys.path:\n",
    "    sys.path.insert(0, PIPELINE_DIR)\n",
    "\n",
    "import importlib\n",
    "import pipeline_utils as pu\n",
    "importlib.reload(pu)\n",
    "\n",
    "# HuggingFace Login\n",
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "login(token=userdata.get(\"HF_TOKEN\"))\n",
    "\n",
    "# Auto-Shutdown Watchdog\n",
    "import threading, time as _time\n",
    "MAX_RUNTIME_HOURS = 6  # Phase 2 braucht evtl. etwas laenger (20 Trials)\n",
    "\n",
    "def _auto_shutdown():\n",
    "    \"\"\"Beendet Runtime nach MAX_RUNTIME_HOURS als Sicherheitsnetz.\"\"\"\n",
    "    _time.sleep(MAX_RUNTIME_HOURS * 3600)\n",
    "    print(f\"\\n[WATCHDOG] Max Runtime ({MAX_RUNTIME_HOURS}h) erreicht. Runtime wird beendet.\")\n",
    "    try:\n",
    "        from google.colab import runtime\n",
    "        runtime.unassign()\n",
    "    except Exception:\n",
    "        pass\n",
    "threading.Thread(target=_auto_shutdown, daemon=True).start()\n",
    "\n",
    "print(f\"Reports-Ordner: {pu.REPORTS_DIR}\")\n",
    "print(f\"Setup abgeschlossen. Watchdog: Runtime wird nach max {MAX_RUNTIME_HOURS}h beendet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== HPT PHASE 2 CONFIGURATION =====\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "MODEL_ID = \"EuroBERT/EuroBERT-210m\"\n",
    "MODEL_SHORT_NAME = \"eurobert_210m\"\n",
    "MAX_LENGTH = 2048\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# ----- Cross-Validation -----\n",
    "N_FOLDS = 3\n",
    "\n",
    "# ----- Optuna -----\n",
    "N_TRIALS = 20  # Mehr Trials im engeren Suchraum\n",
    "STUDY_NAME = \"eurobert_210m_hpt_phase2\"\n",
    "OPTUNA_SEED = 42\n",
    "OPTUNA_TIMEOUT = None\n",
    "\n",
    "# ----- Fixed Training Parameters -----\n",
    "FIXED_GRADIENT_CHECKPOINTING = False\n",
    "FIXED_LOGGING_STEPS = 10\n",
    "FIXED_REPORT_TO = \"tensorboard\"\n",
    "FIXED_DATALOADER_NUM_WORKERS = 4\n",
    "FIXED_EARLY_STOPPING_PATIENCE = 3\n",
    "FIXED_GROUP_BY_LENGTH = True\n",
    "\n",
    "# Mixed Precision: GPU-adaptiv\n",
    "if torch.cuda.is_available():\n",
    "    _gpu_cap = torch.cuda.get_device_capability()\n",
    "    _gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    if _gpu_cap[0] >= 8:\n",
    "        FIXED_BF16 = True\n",
    "        FIXED_FP16 = False\n",
    "    else:\n",
    "        FIXED_BF16 = False\n",
    "        FIXED_FP16 = True\n",
    "    FIXED_OPTIM = \"adamw_torch_fused\"\n",
    "    if _gpu_mem >= 40:\n",
    "        FIXED_BATCH_SIZE_EVAL = 32\n",
    "    elif _gpu_mem >= 20:\n",
    "        FIXED_BATCH_SIZE_EVAL = 16\n",
    "    else:\n",
    "        FIXED_BATCH_SIZE_EVAL = 8\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} ({_gpu_mem:.1f} GB, CC {_gpu_cap[0]}.{_gpu_cap[1]})\")\n",
    "    print(f\"  FP16={FIXED_FP16}, BF16={FIXED_BF16}, Eval Batch={FIXED_BATCH_SIZE_EVAL}\")\n",
    "    print(f\"  Gradient Checkpointing: {FIXED_GRADIENT_CHECKPOINTING}\")\n",
    "else:\n",
    "    raise RuntimeError(\"HPT benoetigt eine GPU! Bitte Colab Runtime aendern.\")\n",
    "\n",
    "# ----- Phase 2: Eingeengte Suchbereiche (basierend auf Phase 1 Top 5) -----\n",
    "# Phase 1 Top 5 Ranges:\n",
    "#   learning_rate:      3.7e-5 .. 5.0e-5\n",
    "#   weight_decay:       0.029  .. 0.071\n",
    "#   warmup_ratio:       0.083  .. 0.145\n",
    "#   label_smoothing:    0.023  .. 0.067\n",
    "#   classifier_dropout: 0.264  .. 0.395\n",
    "#   epochs:             13 .. 15\n",
    "#   scheduler:          linear (4/5)\n",
    "#   batch_size:         4 (4/5)\n",
    "HP_RANGES = {\n",
    "    \"learning_rate\": (2.5e-5, 5.5e-5),              # leicht erweitert (log scale)\n",
    "    \"weight_decay\": (0.02, 0.08),\n",
    "    \"warmup_ratio\": (0.06, 0.16),\n",
    "    \"label_smoothing_factor\": (0.01, 0.08),\n",
    "    \"classifier_dropout\": (0.20, 0.45),\n",
    "    \"num_train_epochs\": (12, 16),                    # int range\n",
    "}\n",
    "\n",
    "# Fixiert aus Phase 1 Erkenntnissen:\n",
    "FIXED_LR_SCHEDULER_TYPE = \"linear\"       # 4/5 Top Trials\n",
    "FIXED_BATCH_SIZE_TRAIN = 4               # 4/5 Top Trials\n",
    "EFFECTIVE_BATCH_SIZE = 16\n",
    "FIXED_GRAD_ACCUM = EFFECTIVE_BATCH_SIZE // FIXED_BATCH_SIZE_TRAIN  # = 4\n",
    "\n",
    "# ----- Labels -----\n",
    "ALL_LABELS = [\n",
    "    \"Klima / Energie\", \"Zuwanderung\", \"Renten\", \"Soziales Gef\\u00e4lle\",\n",
    "    \"AfD/Rechte\", \"Arbeitslosigkeit\", \"Wirtschaftslage\", \"Politikverdruss\",\n",
    "    \"Gesundheitswesen, Pflege\", \"Kosten/L\\u00f6hne/Preise\",\n",
    "    \"Ukraine/Krieg/Russland\", \"Bundeswehr/Verteidigung\", \"Andere\",\n",
    "]\n",
    "\n",
    "# Split-Konfiguration\n",
    "TEST_PER_CLASS = 30\n",
    "\n",
    "print(f\"\\nOptuna HPT Phase 2: {N_TRIALS} Trials, {N_FOLDS}-Fold CV\")\n",
    "print(f\"Modell: {MODEL_ID}\")\n",
    "print(f\"Max Length: {MAX_LENGTH}\")\n",
    "print(f\"Fixiert: scheduler={FIXED_LR_SCHEDULER_TYPE}, batch_size={FIXED_BATCH_SIZE_TRAIN}, grad_accum={FIXED_GRAD_ACCUM}\")\n",
    "print(f\"Effektive Batch Size: {EFFECTIVE_BATCH_SIZE}\")\n",
    "print(f\"Labels: {len(ALL_LABELS)} Klassen\")\n",
    "print(f\"\\nEingeengte Suchbereiche:\")\n",
    "for k, v in HP_RANGES.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DATEN LADEN & CUSTOM SPLIT =====\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "ds = load_dataset(pu.DATASET_ID)\n",
    "train_hf = ds[\"train\"].to_pandas()\n",
    "test_hf = ds[\"test\"].to_pandas()\n",
    "all_labelled = pd.concat([train_hf, test_hf], ignore_index=True)\n",
    "\n",
    "print(f\"Gesamtpool gelabelter Artikel: {len(all_labelled)}\")\n",
    "print(f\"Klassen im Datensatz: {all_labelled['label'].nunique()}\")\n",
    "print()\n",
    "\n",
    "# --- Test-Split (identisch wie Phase 1) ---\n",
    "test_indices = []\n",
    "rest_indices = []\n",
    "\n",
    "for label in ALL_LABELS:\n",
    "    label_mask = all_labelled[\"label\"] == label\n",
    "    label_indices = all_labelled[label_mask].index.tolist()\n",
    "    n_total = len(label_indices)\n",
    "\n",
    "    if n_total < 60:\n",
    "        n_test = n_total // 2\n",
    "        print(f\"  {label}: nur {n_total} Artikel -> {n_test} fuer Test (Haelfte)\")\n",
    "    else:\n",
    "        n_test = TEST_PER_CLASS\n",
    "\n",
    "    np.random.shuffle(label_indices)\n",
    "    test_indices.extend(label_indices[:n_test])\n",
    "    rest_indices.extend(label_indices[n_test:])\n",
    "\n",
    "test_df = all_labelled.loc[test_indices].reset_index(drop=True)\n",
    "cv_pool_df = all_labelled.loc[rest_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTest (eingefroren):  {len(test_df)} Artikel\")\n",
    "print(f\"CV-Pool (fuer Folds): {len(cv_pool_df)} Artikel\")\n",
    "\n",
    "# Klassenverteilung\n",
    "print(\"\\nCV-Pool Klassenverteilung:\")\n",
    "cv_dist = cv_pool_df[\"label\"].value_counts().sort_index()\n",
    "for label, count in cv_dist.items():\n",
    "    print(f\"  {label}: {count}\")\n",
    "print(f\"  TOTAL: {len(cv_pool_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LABEL ENCODING =====\n",
    "label2id = {label: idx for idx, label in enumerate(ALL_LABELS)}\n",
    "id2label = {idx: label for idx, label in enumerate(ALL_LABELS)}\n",
    "\n",
    "cv_pool_df[\"label_id\"] = cv_pool_df[\"label\"].map(label2id)\n",
    "test_df[\"label_id\"] = test_df[\"label\"].map(label2id)\n",
    "\n",
    "assert cv_pool_df[\"label_id\"].isna().sum() == 0, \"Unbekannte Labels im CV-Pool!\"\n",
    "assert test_df[\"label_id\"].isna().sum() == 0, \"Unbekannte Labels im Test-Set!\"\n",
    "\n",
    "print(\"Label-Mapping:\")\n",
    "for label, idx in label2id.items():\n",
    "    print(f\"  {idx:>2}: {label}\")\n",
    "print(f\"\\nAnzahl Klassen: {len(ALL_LABELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TOKENIZER + EUROBERT ROPE FIX =====\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.modeling_rope_utils import ROPE_INIT_FUNCTIONS\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "def _default_rope_init(config, device=None, **kwargs):\n",
    "    base = getattr(config, \"rope_theta\", 10000.0)\n",
    "    partial_rotary_factor = getattr(config, \"partial_rotary_factor\", 1.0)\n",
    "    head_dim = getattr(config, \"head_dim\", config.hidden_size // config.num_attention_heads)\n",
    "    dim = int(head_dim * partial_rotary_factor)\n",
    "    inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.int64).float().to(device) / dim))\n",
    "    return inv_freq, 1.0\n",
    "\n",
    "ROPE_INIT_FUNCTIONS[\"default\"] = _default_rope_init\n",
    "print(\"ROPE_INIT_FUNCTIONS gepatcht.\")\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "print(f\"Tokenizer geladen: {MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OPTUNA OBJECTIVE MIT K-FOLD CV =====\n",
    "import gc\n",
    "import shutil\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Fold-Indizes vorab berechnen\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "fold_indices = list(skf.split(cv_pool_df, cv_pool_df[\"label_id\"]))\n",
    "\n",
    "print(f\"Stratified {N_FOLDS}-Fold CV:\")\n",
    "for i, (train_idx, val_idx) in enumerate(fold_indices):\n",
    "    val_labels = cv_pool_df.iloc[val_idx][\"label\"].value_counts()\n",
    "    min_val_count = val_labels.min()\n",
    "    min_val_class = val_labels.idxmin()\n",
    "    print(f\"  Fold {i+1}: Train={len(train_idx)}, Val={len(val_idx)}, \"\n",
    "          f\"min Val-Klasse: {min_val_class} ({min_val_count} Samples)\")\n",
    "\n",
    "\n",
    "def compute_metrics_simple(eval_pred):\n",
    "    \"\"\"Nur F1 Macro — schlank fuer HPT.\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "    }\n",
    "\n",
    "\n",
    "def create_model(classifier_dropout):\n",
    "    \"\"\"Erstellt ein frisches Modell mit dem angegebenen Dropout.\"\"\"\n",
    "    config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "    config.num_labels = len(ALL_LABELS)\n",
    "    config.id2label = id2label\n",
    "    config.label2id = label2id\n",
    "    config.classifier_dropout = classifier_dropout\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        config=config,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def _cleanup_cuda():\n",
    "    \"\"\"VRAM aufraeumen.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective: mean F1 Macro across k folds.\"\"\"\n",
    "\n",
    "    # --- Hyperparameter samplen (eingeengter Bereich) ---\n",
    "    lr = trial.suggest_float(\"learning_rate\", *HP_RANGES[\"learning_rate\"], log=True)\n",
    "    wd = trial.suggest_float(\"weight_decay\", *HP_RANGES[\"weight_decay\"])\n",
    "    warmup = trial.suggest_float(\"warmup_ratio\", *HP_RANGES[\"warmup_ratio\"])\n",
    "    label_smooth = trial.suggest_float(\"label_smoothing_factor\", *HP_RANGES[\"label_smoothing_factor\"])\n",
    "    dropout = trial.suggest_float(\"classifier_dropout\", *HP_RANGES[\"classifier_dropout\"])\n",
    "    epochs = trial.suggest_int(\"num_train_epochs\", *HP_RANGES[\"num_train_epochs\"])\n",
    "\n",
    "    # Fixierte Parameter aus Phase 1\n",
    "    scheduler = FIXED_LR_SCHEDULER_TYPE\n",
    "    batch_size = FIXED_BATCH_SIZE_TRAIN\n",
    "    grad_accum = FIXED_GRAD_ACCUM\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Trial {trial.number}: lr={lr:.2e}, wd={wd:.3f}, warmup={warmup:.3f}, \"\n",
    "          f\"ls={label_smooth:.3f}, dropout={dropout:.3f}, epochs={epochs}\")\n",
    "    print(f\"  (fixiert: sched={scheduler}, batch={batch_size}, grad_accum={grad_accum})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(fold_indices):\n",
    "        print(f\"  Fold {fold_idx + 1}/{N_FOLDS}...\", end=\" \", flush=True)\n",
    "\n",
    "        _cleanup_cuda()\n",
    "\n",
    "        # --- Fold Datasets ---\n",
    "        fold_train_df = cv_pool_df.iloc[train_idx]\n",
    "        fold_val_df = cv_pool_df.iloc[val_idx]\n",
    "\n",
    "        train_ds = Dataset.from_pandas(\n",
    "            fold_train_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"})\n",
    "        )\n",
    "        val_ds = Dataset.from_pandas(\n",
    "            fold_val_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"})\n",
    "        )\n",
    "\n",
    "        train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "        val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "        train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "        val_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "        fold_output_dir = f\"/content/hpt_tmp/trial_{trial.number}_fold_{fold_idx}\"\n",
    "        fold_logging_dir = f\"/content/hpt_tmp/tb_logs/trial_{trial.number:03d}_fold_{fold_idx}\"\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=fold_output_dir,\n",
    "            num_train_epochs=epochs,\n",
    "            learning_rate=lr,\n",
    "            weight_decay=wd,\n",
    "            warmup_ratio=warmup,\n",
    "            label_smoothing_factor=label_smooth,\n",
    "            lr_scheduler_type=scheduler,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=FIXED_BATCH_SIZE_EVAL,\n",
    "            gradient_accumulation_steps=grad_accum,\n",
    "            bf16=FIXED_BF16,\n",
    "            fp16=FIXED_FP16,\n",
    "            gradient_checkpointing=FIXED_GRADIENT_CHECKPOINTING,\n",
    "            optim=FIXED_OPTIM,\n",
    "            group_by_length=FIXED_GROUP_BY_LENGTH,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            save_total_limit=1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1_macro\",\n",
    "            greater_is_better=True,\n",
    "            logging_strategy=\"steps\",\n",
    "            logging_steps=FIXED_LOGGING_STEPS,\n",
    "            logging_dir=fold_logging_dir,\n",
    "            report_to=FIXED_REPORT_TO,\n",
    "            seed=RANDOM_SEED + fold_idx,\n",
    "            dataloader_num_workers=FIXED_DATALOADER_NUM_WORKERS,\n",
    "            dataloader_pin_memory=True,\n",
    "            disable_tqdm=False,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model = create_model(dropout)\n",
    "\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_ds,\n",
    "                eval_dataset=val_ds,\n",
    "                data_collator=data_collator,\n",
    "                compute_metrics=compute_metrics_simple,\n",
    "                callbacks=[EarlyStoppingCallback(early_stopping_patience=FIXED_EARLY_STOPPING_PATIENCE)],\n",
    "            )\n",
    "\n",
    "            trainer.train()\n",
    "\n",
    "            eval_result = trainer.evaluate()\n",
    "            fold_f1 = eval_result[\"eval_f1_macro\"]\n",
    "\n",
    "            # NaN-Detection: sofort prunen wenn Loss NaN\n",
    "            if np.isnan(eval_result.get(\"eval_loss\", 0)) or fold_f1 < 0.05:\n",
    "                print(f\"NaN/collapse detected (F1={fold_f1:.4f}) — pruning Trial\")\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "            fold_scores.append(fold_f1)\n",
    "            print(f\"F1 Macro = {fold_f1:.4f}\")\n",
    "\n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(f\"\\n  OOM in Trial {trial.number}, Fold {fold_idx + 1}! Ueberspringe Trial.\")\n",
    "            _cleanup_cuda()\n",
    "            if os.path.exists(fold_output_dir):\n",
    "                shutil.rmtree(fold_output_dir, ignore_errors=True)\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        finally:\n",
    "            for var in [\"trainer\", \"model\", \"training_args\", \"train_ds\", \"val_ds\"]:\n",
    "                try:\n",
    "                    exec(f\"del {var}\")\n",
    "                except NameError:\n",
    "                    pass\n",
    "            _cleanup_cuda()\n",
    "            if os.path.exists(fold_output_dir):\n",
    "                shutil.rmtree(fold_output_dir, ignore_errors=True)\n",
    "\n",
    "        # Pruning: Zwischenergebnis melden\n",
    "        trial.report(np.mean(fold_scores), fold_idx)\n",
    "        if trial.should_prune():\n",
    "            print(f\"  Trial {trial.number} PRUNED nach Fold {fold_idx + 1}\")\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    mean_f1 = np.mean(fold_scores)\n",
    "    std_f1 = np.std(fold_scores)\n",
    "    print(f\"\\n  -> Trial {trial.number}: F1 Macro = {mean_f1:.4f} +/- {std_f1:.4f}\")\n",
    "\n",
    "    return mean_f1\n",
    "\n",
    "\n",
    "print(\"Objective Function definiert.\")\n",
    "print(f\"Folds: {N_FOLDS}, Trials: {N_TRIALS}\")\n",
    "print(f\"Effektive Batch Size: {EFFECTIVE_BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OPTUNA STUDY STARTEN =====\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from pathlib import Path\n",
    "\n",
    "# SQLite-Backend auf Google Drive fuer Crash-Recovery\n",
    "db_dir = Path(pu.REPORTS_DIR)\n",
    "db_dir.mkdir(parents=True, exist_ok=True)\n",
    "storage_path = db_dir / \"hpt_eurobert_210m_phase2.db\"\n",
    "storage_url = f\"sqlite:///{storage_path}\"\n",
    "\n",
    "print(f\"Optuna DB: {storage_path}\")\n",
    "print(f\"  -> Bei Crash: Runtime neu starten, 'Run All' -> Trials werden fortgesetzt\")\n",
    "\n",
    "sampler = TPESampler(seed=OPTUNA_SEED, n_startup_trials=5)\n",
    "pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=1)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=STUDY_NAME,\n",
    "    direction=\"maximize\",\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    "    storage=storage_url,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# Nur fehlende Trials nachlaufen lassen (Fix aus Phase 1 Bug)\n",
    "n_existing = len([t for t in study.trials if t.state.name == \"COMPLETE\"])\n",
    "n_remaining = max(0, N_TRIALS - n_existing)\n",
    "\n",
    "if n_existing > 0:\n",
    "    print(f\"\\n{n_existing} bereits abgeschlossene Trials gefunden.\")\n",
    "    print(f\"Noch {n_remaining} Trials ausstehend.\")\n",
    "\n",
    "if n_remaining == 0:\n",
    "    print(\"Alle Trials bereits abgeschlossen — ueberspringe optimize().\")\n",
    "else:\n",
    "    timer_hpt = pu.ExperimentTimer()\n",
    "    with timer_hpt:\n",
    "        study.optimize(\n",
    "            objective,\n",
    "            n_trials=n_remaining,\n",
    "            timeout=OPTUNA_TIMEOUT,\n",
    "            gc_after_trial=True,\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "    print(f\"\\nOptuna HPT Phase 2 abgeschlossen: {timer_hpt.duration_formatted}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Beste Trial: {study.best_trial.number}\")\n",
    "print(f\"Bester F1 Macro (CV Mean): {study.best_value:.4f}\")\n",
    "print(f\"\\nBeste Hyperparameter:\")\n",
    "for key, val in study.best_params.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ERGEBNISSE ANALYSIEREN =====\n",
    "\n",
    "trials_df = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\", \"duration\"))\n",
    "trials_df = trials_df.sort_values(\"value\", ascending=False)\n",
    "\n",
    "completed = trials_df[trials_df[\"state\"] == \"COMPLETE\"].copy()\n",
    "pruned = trials_df[trials_df[\"state\"] == \"PRUNED\"].copy()\n",
    "\n",
    "print(f\"Trials: {len(completed)} abgeschlossen, {len(pruned)} gepruned\")\n",
    "print(f\"\\nTop 5 Trials:\")\n",
    "top5_cols = [\"number\", \"value\"] + [c for c in completed.columns if c.startswith(\"params_\")]\n",
    "print(completed[top5_cols].head().to_string(index=False))\n",
    "\n",
    "print(f\"\\nStatistiken ueber alle abgeschlossenen Trials:\")\n",
    "print(f\"  Mean F1:   {completed['value'].mean():.4f}\")\n",
    "print(f\"  Std F1:    {completed['value'].std():.4f}\")\n",
    "print(f\"  Min F1:    {completed['value'].min():.4f}\")\n",
    "print(f\"  Max F1:    {completed['value'].max():.4f}\")\n",
    "\n",
    "# Vergleich mit Phase 1\n",
    "print(f\"\\n--- Vergleich mit Phase 1 ---\")\n",
    "print(f\"  Phase 1 Best: 0.8393\")\n",
    "print(f\"  Phase 2 Best: {study.best_value:.4f}\")\n",
    "print(f\"  Differenz:    {study.best_value - 0.8393:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OPTUNA VISUALISIERUNGEN =====\n",
    "import optuna.visualization as vis\n",
    "\n",
    "# 1. Optimization History\n",
    "fig_history = vis.plot_optimization_history(study)\n",
    "fig_history.update_layout(title=\"Phase 2: Optimization History\")\n",
    "fig_history.show()\n",
    "\n",
    "# 2. Parameter Importances\n",
    "try:\n",
    "    fig_importance = vis.plot_param_importances(study)\n",
    "    fig_importance.update_layout(title=\"Phase 2: Parameter Importance (fANOVA)\")\n",
    "    fig_importance.show()\n",
    "except Exception as e:\n",
    "    print(f\"Parameter Importance nicht verfuegbar: {e}\")\n",
    "\n",
    "# 3. Parallel Coordinate Plot\n",
    "fig_parallel = vis.plot_parallel_coordinate(study)\n",
    "fig_parallel.update_layout(title=\"Phase 2: Parallel Coordinate\")\n",
    "fig_parallel.show()\n",
    "\n",
    "# 4. Slice Plot\n",
    "fig_slice = vis.plot_slice(study)\n",
    "fig_slice.show()\n",
    "\n",
    "# 5. Contour: LR vs Dropout\n",
    "try:\n",
    "    fig_contour = vis.plot_contour(study, params=[\"learning_rate\", \"classifier_dropout\"])\n",
    "    fig_contour.update_layout(title=\"Phase 2: LR vs. Dropout\")\n",
    "    fig_contour.show()\n",
    "except Exception as e:\n",
    "    print(f\"Contour Plot nicht verfuegbar: {e}\")\n",
    "\n",
    "print(\"Optuna-Visualisierungen erstellt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SUMMARY-VISUALISIERUNG (matplotlib) =====\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Trial F1 Scores (sortiert)\n",
    "completed_sorted = completed.sort_values(\"value\", ascending=True).reset_index(drop=True)\n",
    "ax = axes[0, 0]\n",
    "best_idx = completed_sorted[\"value\"].idxmax()\n",
    "colors = [\"#4CAF50\" if i == best_idx else \"#2196F3\" for i in range(len(completed_sorted))]\n",
    "ax.barh(range(len(completed_sorted)), completed_sorted[\"value\"], color=colors)\n",
    "ax.set_xlabel(\"F1 Macro (CV Mean)\")\n",
    "ax.set_ylabel(\"Trial (sortiert)\")\n",
    "ax.set_title(\"Alle Trials sortiert nach F1 Macro\")\n",
    "ax.axvline(x=study.best_value, color=\"red\", linestyle=\"--\", alpha=0.7,\n",
    "           label=f\"Best: {study.best_value:.4f}\")\n",
    "# Phase 1 Referenzlinie\n",
    "ax.axvline(x=0.8393, color=\"orange\", linestyle=\":\", alpha=0.7,\n",
    "           label=\"Phase 1 Best: 0.8393\")\n",
    "ax.legend()\n",
    "ax.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "# 2. Learning Rate vs F1\n",
    "ax = axes[0, 1]\n",
    "scatter = ax.scatter(\n",
    "    completed[\"params_learning_rate\"], completed[\"value\"],\n",
    "    c=completed[\"value\"], cmap=\"viridis\", s=80, edgecolors=\"black\", linewidth=0.5,\n",
    ")\n",
    "ax.set_xlabel(\"Learning Rate\")\n",
    "ax.set_ylabel(\"F1 Macro\")\n",
    "ax.set_title(\"Learning Rate vs. F1 Macro\")\n",
    "ax.set_xscale(\"log\")\n",
    "plt.colorbar(scatter, ax=ax, label=\"F1\")\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 3. Beste Hyperparameter (normalisiert)\n",
    "ax = axes[1, 0]\n",
    "continuous_params = [\"learning_rate\", \"weight_decay\", \"warmup_ratio\",\n",
    "                     \"label_smoothing_factor\", \"classifier_dropout\"]\n",
    "best_normalized = []\n",
    "for p in continuous_params:\n",
    "    lo, hi = HP_RANGES[p]\n",
    "    best_val = study.best_params[p]\n",
    "    if p == \"learning_rate\":\n",
    "        import math\n",
    "        best_normalized.append((math.log(best_val) - math.log(lo)) / (math.log(hi) - math.log(lo)))\n",
    "    elif hi == lo:\n",
    "        best_normalized.append(0.5)\n",
    "    else:\n",
    "        best_normalized.append((best_val - lo) / (hi - lo))\n",
    "ax.barh(continuous_params, best_normalized, color=\"#FF9800\")\n",
    "ax.set_xlabel(\"Normalisierter Wert (0=min, 1=max)\")\n",
    "ax.set_title(\"Beste Hyperparameter (normalisiert)\")\n",
    "ax.set_xlim(0, 1)\n",
    "for i, p in enumerate(continuous_params):\n",
    "    val = study.best_params[p]\n",
    "    ax.text(best_normalized[i] + 0.02, i, f\"{val:.4g}\", va=\"center\", fontsize=9)\n",
    "ax.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "# 4. Phase 1 vs Phase 2 Vergleich\n",
    "ax = axes[1, 1]\n",
    "phase1_best = 0.8393\n",
    "phase2_scores = completed[\"value\"].sort_values(ascending=False).values\n",
    "ax.plot(range(1, len(phase2_scores) + 1), phase2_scores, 'o-', color=\"#2196F3\", label=\"Phase 2 Trials\")\n",
    "ax.axhline(y=phase1_best, color=\"orange\", linestyle=\"--\", linewidth=2, label=f\"Phase 1 Best: {phase1_best:.4f}\")\n",
    "ax.axhline(y=study.best_value, color=\"green\", linestyle=\"--\", linewidth=2, label=f\"Phase 2 Best: {study.best_value:.4f}\")\n",
    "ax.set_xlabel(\"Trial Rank\")\n",
    "ax.set_ylabel(\"F1 Macro\")\n",
    "ax.set_title(\"Phase 1 vs Phase 2 Performance\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"HPT Phase 2: EuroBERT-210M ({len(completed)} Trials, {N_FOLDS}-Fold CV)\",\n",
    "    fontsize=14, fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_dir = Path(pu.REPORTS_DIR)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "png_path = save_dir / \"hpt_eurobert_210m_phase2_summary.png\"\n",
    "fig.savefig(str(png_path), dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Plot gespeichert: {png_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== HPT REPORT GENERIEREN =====\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "report_name = f\"{now.strftime('%d%m%y')}_{MODEL_SHORT_NAME}_hpt_phase2\"\n",
    "\n",
    "# Timer-Dauer (falls optimize() gelaufen ist)\n",
    "duration_str = timer_hpt.duration_formatted if 'timer_hpt' in dir() else \"N/A (aus DB geladen)\"\n",
    "\n",
    "# --- Markdown Report ---\n",
    "report_lines = [\n",
    "    f\"# HPT Report: EuroBERT-210M Phase 2\",\n",
    "    f\"**Generated:** {now.strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    \"\",\n",
    "    \"---\",\n",
    "    \"\",\n",
    "    \"## Phase 1 -> Phase 2\",\n",
    "    f\"- Phase 1 Best F1: **0.8393** (Trial 11)\",\n",
    "    f\"- Phase 2 Best F1: **{study.best_value:.4f}** (Trial {study.best_trial.number})\",\n",
    "    f\"- Verbesserung: **{study.best_value - 0.8393:+.4f}**\",\n",
    "    \"\",\n",
    "    \"## Configuration\",\n",
    "    \"| Property | Value |\",\n",
    "    \"|---|---|\",\n",
    "    f\"| Model | {MODEL_ID} |\",\n",
    "    f\"| N Trials | {N_TRIALS} |\",\n",
    "    f\"| N Folds | {N_FOLDS} |\",\n",
    "    f\"| Completed Trials | {len(completed)} |\",\n",
    "    f\"| Pruned Trials | {len(pruned)} |\",\n",
    "    f\"| Duration | {duration_str} |\",\n",
    "    f\"| GPU | {pu.get_gpu_info()['gpu_name']} |\",\n",
    "    f\"| CV Pool Size | {len(cv_pool_df)} |\",\n",
    "    f\"| Test Size (frozen) | {len(test_df)} |\",\n",
    "    f\"| Effective Batch Size | {EFFECTIVE_BATCH_SIZE} |\",\n",
    "    \"\",\n",
    "    \"## Fixed Parameters (aus Phase 1)\",\n",
    "    \"| Parameter | Value |\",\n",
    "    \"|---|---|\",\n",
    "    f\"| lr_scheduler_type | {FIXED_LR_SCHEDULER_TYPE} |\",\n",
    "    f\"| per_device_train_batch_size | {FIXED_BATCH_SIZE_TRAIN} |\",\n",
    "    f\"| gradient_accumulation_steps | {FIXED_GRAD_ACCUM} |\",\n",
    "    f\"| bf16 | {FIXED_BF16} |\",\n",
    "    f\"| fp16 | {FIXED_FP16} |\",\n",
    "    f\"| gradient_checkpointing | {FIXED_GRADIENT_CHECKPOINTING} |\",\n",
    "    f\"| group_by_length | {FIXED_GROUP_BY_LENGTH} |\",\n",
    "    f\"| optim | {FIXED_OPTIM} |\",\n",
    "    f\"| early_stopping_patience | {FIXED_EARLY_STOPPING_PATIENCE} |\",\n",
    "    f\"| max_length | {MAX_LENGTH} |\",\n",
    "    \"\",\n",
    "    \"## Eingeengte Suchbereiche (Phase 2)\",\n",
    "    \"| Parameter | Range |\",\n",
    "    \"|---|---|\",\n",
    "]\n",
    "for param, range_val in HP_RANGES.items():\n",
    "    report_lines.append(f\"| {param} | {range_val} |\")\n",
    "\n",
    "report_lines += [\n",
    "    \"\",\n",
    "    \"## Beste Hyperparameter\",\n",
    "    \"| Parameter | Value |\",\n",
    "    \"|---|---|\",\n",
    "]\n",
    "for key, val in study.best_params.items():\n",
    "    report_lines.append(f\"| **{key}** | **{val}** |\")\n",
    "# Fixierte Parameter auch auflisten\n",
    "report_lines.append(f\"| **lr_scheduler_type** | **{FIXED_LR_SCHEDULER_TYPE}** (fixiert) |\")\n",
    "report_lines.append(f\"| **per_device_train_batch_size** | **{FIXED_BATCH_SIZE_TRAIN}** (fixiert) |\")\n",
    "\n",
    "report_lines += [\n",
    "    \"\",\n",
    "    f\"**Best F1 Macro (CV Mean): {study.best_value:.4f}**\",\n",
    "    f\"**Best Trial: {study.best_trial.number}**\",\n",
    "    \"\",\n",
    "    \"## Alle Trials\",\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "table_cols = [\"number\", \"value\", \"state\"] + [c for c in trials_df.columns if c.startswith(\"params_\")]\n",
    "report_lines.append(trials_df[table_cols].to_markdown(index=False))\n",
    "report_lines += [\n",
    "    \"\",\n",
    "    \"---\",\n",
    "    \"*Generated by eurobert_210_hpt_phase_2.ipynb*\",\n",
    "]\n",
    "\n",
    "report_md = \"\\n\".join(report_lines)\n",
    "report_path = Path(pu.REPORTS_DIR) / f\"{report_name}.md\"\n",
    "report_path.write_text(report_md, encoding=\"utf-8\")\n",
    "\n",
    "# --- JSON Sidecar ---\n",
    "json_data = {\n",
    "    \"report_id\": report_name,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"phase\": 2,\n",
    "    \"phase1_best_value\": 0.8393,\n",
    "    \"n_trials\": N_TRIALS,\n",
    "    \"n_folds\": N_FOLDS,\n",
    "    \"best_value\": round(study.best_value, 4),\n",
    "    \"best_trial_number\": study.best_trial.number,\n",
    "    \"best_params\": {\n",
    "        **study.best_params,\n",
    "        \"lr_scheduler_type\": FIXED_LR_SCHEDULER_TYPE,\n",
    "        \"per_device_train_batch_size\": FIXED_BATCH_SIZE_TRAIN,\n",
    "    },\n",
    "    \"all_trials\": [\n",
    "        {\n",
    "            \"number\": t.number,\n",
    "            \"value\": round(t.value, 4) if t.value is not None else None,\n",
    "            \"params\": t.params,\n",
    "            \"state\": str(t.state.name),\n",
    "            \"duration_s\": round(t.duration.total_seconds(), 1) if t.duration else None,\n",
    "        }\n",
    "        for t in study.trials\n",
    "    ],\n",
    "    \"search_ranges\": {k: str(v) for k, v in HP_RANGES.items()},\n",
    "    \"fixed_params\": {\n",
    "        \"lr_scheduler_type\": FIXED_LR_SCHEDULER_TYPE,\n",
    "        \"per_device_train_batch_size\": FIXED_BATCH_SIZE_TRAIN,\n",
    "        \"gradient_accumulation_steps\": FIXED_GRAD_ACCUM,\n",
    "        \"bf16\": FIXED_BF16,\n",
    "        \"fp16\": FIXED_FP16,\n",
    "        \"gradient_checkpointing\": FIXED_GRADIENT_CHECKPOINTING,\n",
    "        \"optim\": FIXED_OPTIM,\n",
    "        \"early_stopping_patience\": FIXED_EARLY_STOPPING_PATIENCE,\n",
    "        \"group_by_length\": FIXED_GROUP_BY_LENGTH,\n",
    "        \"max_length\": MAX_LENGTH,\n",
    "        \"effective_batch_size\": EFFECTIVE_BATCH_SIZE,\n",
    "    },\n",
    "    \"duration_formatted\": duration_str,\n",
    "    \"gpu\": pu.get_gpu_info(),\n",
    "}\n",
    "json_path = Path(pu.REPORTS_DIR) / f\"{report_name}.json\"\n",
    "json_path.write_text(json.dumps(json_data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Report: {report_path}\")\n",
    "print(f\"JSON:   {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FINALE PARAMETER FUER TRAINING =====\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"  FINALE HYPERPARAMETER (kopieren fuer finales Training)\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"# Aus HPT Phase 2 ({datetime.now().strftime('%Y-%m-%d')})\")\n",
    "print(f\"# Best F1 Macro (CV Mean): {study.best_value:.4f}\")\n",
    "print(f\"# Phase 1 Best: 0.8393 -> Phase 2 Best: {study.best_value:.4f} ({study.best_value - 0.8393:+.4f})\")\n",
    "print(f\"# Trial {study.best_trial.number}\")\n",
    "print()\n",
    "print(f\"LEARNING_RATE = {study.best_params['learning_rate']}\")\n",
    "print(f\"WEIGHT_DECAY = {study.best_params['weight_decay']}\")\n",
    "print(f\"WARMUP_RATIO = {study.best_params['warmup_ratio']}\")\n",
    "print(f\"LABEL_SMOOTHING_FACTOR = {study.best_params['label_smoothing_factor']}\")\n",
    "print(f'LR_SCHEDULER_TYPE = \"{FIXED_LR_SCHEDULER_TYPE}\"')\n",
    "print(f\"CLASSIFIER_DROPOUT = {study.best_params['classifier_dropout']}\")\n",
    "print(f\"PER_DEVICE_TRAIN_BATCH_SIZE = {FIXED_BATCH_SIZE_TRAIN}\")\n",
    "print(f\"NUM_TRAIN_EPOCHS = {study.best_params['num_train_epochs']}\")\n",
    "print()\n",
    "print(\"# Fixed parameters:\")\n",
    "print(f\"BF16 = {FIXED_BF16}\")\n",
    "print(f\"GRADIENT_CHECKPOINTING = {FIXED_GRADIENT_CHECKPOINTING}\")\n",
    "print(f'OPTIM = \"{FIXED_OPTIM}\"')\n",
    "print(f\"EARLY_STOPPING_PATIENCE = {FIXED_EARLY_STOPPING_PATIENCE}\")\n",
    "print(f\"GROUP_BY_LENGTH = {FIXED_GROUP_BY_LENGTH}\")\n",
    "print(f\"MAX_LENGTH = {MAX_LENGTH}\")\n",
    "print(f\"EFFECTIVE_BATCH_SIZE = {EFFECTIVE_BATCH_SIZE}\")\n",
    "print(f\"GRADIENT_ACCUMULATION_STEPS = {FIXED_GRAD_ACCUM}\")\n",
    "print()\n",
    "print(\"# Naechster Schritt: Finales Training\")\n",
    "print(\"# -> Training mit diesen Parametern auf dem gesamten CV-Pool\")\n",
    "print(\"# -> Evaluation auf dem eingefrorenen Test-Set\")\n",
    "print(\"# -> Upload auf HuggingFace Hub\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CLEANUP + AUTO-SHUTDOWN =====\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(\"/content/hpt_tmp\"):\n",
    "    for item in Path(\"/content/hpt_tmp\").iterdir():\n",
    "        if item.name != \"tb_logs\":\n",
    "            shutil.rmtree(item, ignore_errors=True)\n",
    "    print(\"Temporaere Checkpoint-Dateien geloescht.\")\n",
    "    print(\"TensorBoard Logs behalten: /content/hpt_tmp/tb_logs/\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    free_mem = torch.cuda.mem_get_info()[0] / 1e9\n",
    "    print(f\"GPU VRAM frei: {free_mem:.1f} GB\")\n",
    "\n",
    "print(f\"\\nErgebnisse auf Google Drive:\")\n",
    "print(f\"  Report: {report_path}\")\n",
    "print(f\"  JSON:   {json_path}\")\n",
    "print(f\"  Plot:   {png_path}\")\n",
    "print(f\"  DB:     {storage_path}\")\n",
    "\n",
    "print(\"\\nRuntime wird beendet...\")\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
