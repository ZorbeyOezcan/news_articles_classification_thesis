{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agX-VMGdiomG"
   },
   "source": "# Fine-Tuning Classification: EuroBERT-2.1B\n## Model: EuroBERT/EuroBERT-2.1B\n\nSingle-label Klassifikation (13 Klassen) mit Hugging Face Trainer API.\nFine-Tuning auf gelabelten deutschen Nachrichtenartikeln (Bundestagswahl 2025).\n\n**Voraussetzung:** GPU-Runtime aktiviert (T4 / L4), `HF_TOKEN` in Colab Secrets hinterlegt."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCc0dkTAiomO",
    "outputId": "b2b8b9d1-752d-4043-ad45-0f6523b842e1"
   },
   "outputs": [],
   "source": [
    "# === SETUP (in jedem Notebook identisch) ===\n",
    "import os, sys\n",
    "\n",
    "# Repo klonen / aktualisieren\n",
    "REPO = \"/content/news_articles_classification_thesis\"\n",
    "if not os.path.exists(REPO):\n",
    "    !git clone https://github.com/ZorbeyOezcan/news_articles_classification_thesis.git {REPO}\n",
    "else:\n",
    "    !cd {REPO} && git pull -q\n",
    "\n",
    "# Dependencies\n",
    "!pip install -q transformers[sentencepiece] datasets huggingface_hub scikit-learn matplotlib seaborn tqdm pandas accelerate evaluate\n",
    "\n",
    "# Google Drive mounten (persistente Reports)\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=False)\n",
    "\n",
    "# pipeline_utils importierbar machen\n",
    "PIPELINE_DIR = f\"{REPO}/Python/classification_pipeline\"\n",
    "if PIPELINE_DIR not in sys.path:\n",
    "    sys.path.insert(0, PIPELINE_DIR)\n",
    "\n",
    "import importlib\n",
    "import pipeline_utils as pu\n",
    "importlib.reload(pu)\n",
    "\n",
    "# HuggingFace Login\n",
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "login(token=userdata.get(\"HF_TOKEN\"))\n",
    "\n",
    "print(f\"Reports-Ordner: {pu.REPORTS_DIR}\")\n",
    "print(\"Setup abgeschlossen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fr5HxKlMiomP",
    "outputId": "9de2b3da-886d-40aa-a433-3b836d2d4d3e"
   },
   "outputs": [],
   "source": "# ===== MODEL CONFIG =====\nMODEL_ID = \"EuroBERT/EuroBERT-2.1B\"\nMODEL_SHORT_NAME = \"eurobert_2_1b\"\nMODEL_TYPE = \"fine-tuned\"\n\n# Trainings-Hyperparameter\nMAX_LENGTH = 2048\n\n# Dynamische Batch Sizes basierend auf verfuegbarer Hardware\nimport torch\nif torch.cuda.is_available():\n    _gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n    if _gpu_mem >= 40:       # A100 (40/80 GB)\n        BATCH_SIZE_TRAIN = 2\n        BATCH_SIZE_EVAL = 8\n        GRADIENT_ACCUMULATION_STEPS = 8\n    elif _gpu_mem >= 20:     # L4 (24 GB)\n        BATCH_SIZE_TRAIN = 1\n        BATCH_SIZE_EVAL = 4\n        GRADIENT_ACCUMULATION_STEPS = 16\n    else:                    # T4 (16 GB)\n        BATCH_SIZE_TRAIN = 1\n        BATCH_SIZE_EVAL = 2\n        GRADIENT_ACCUMULATION_STEPS = 16\n    print(f\"GPU erkannt: {torch.cuda.get_device_name(0)} ({_gpu_mem:.1f} GB)\")\n    print(f\"  -> Batch Size Train: {BATCH_SIZE_TRAIN}, Eval: {BATCH_SIZE_EVAL}, Grad Accum: {GRADIENT_ACCUMULATION_STEPS}\")\nelse:\n    BATCH_SIZE_TRAIN = 2\n    BATCH_SIZE_EVAL = 8\n    GRADIENT_ACCUMULATION_STEPS = 8\n    print(\"WARNUNG: Keine GPU erkannt! Training wird SEHR langsam sein.\")\n    print(\"  -> In Colab: Runtime > Change runtime type > T4 GPU\")\n\nNUM_EPOCHS = 8\nLEARNING_RATE = 2e-5\nWARMUP_RATIO = 0.06\nWEIGHT_DECAY = 0.01\nFP16 = True  # wird in Trainer-Zelle dynamisch angepasst (FP16/BF16/keins)\n\n# Split-Konfiguration\nTEST_PER_CLASS = 30   # Anzahl Testartikel pro Klasse (fix)\nVAL_FRACTION = 0.2    # Anteil der restlichen Daten fuer Validation\n\nRANDOM_SEED = 42\n\n# Label-Liste (muss exakt mit dem Datensatz uebereinstimmen)\nALL_LABELS = [\n    \"Klima / Energie\", \"Zuwanderung\", \"Renten\", \"Soziales Gefälle\",\n    \"AfD/Rechte\", \"Arbeitslosigkeit\", \"Wirtschaftslage\", \"Politikverdruss\",\n    \"Gesundheitswesen, Pflege\", \"Kosten/Löhne/Preise\",\n    \"Ukraine/Krieg/Russland\", \"Bundeswehr/Verteidigung\", \"Andere\",\n]\n\n# ===== MODEL INFO (fuer Report) =====\nMODEL_INFO = {\n    \"huggingface_id\": MODEL_ID,\n    \"language\": \"Multilingual (inkl. Deutsch)\",\n    \"max_tokens\": MAX_LENGTH,\n    \"parameters\": \"2.1B\",\n    \"notes\": \"EuroBERT-2.1B, fine-tuned for single-label classification. Mixed Precision.\",\n}\n\nprint(f\"\\nModell: {MODEL_ID}\")\nprint(f\"Max Length: {MAX_LENGTH}\")\nprint(f\"Effektive Batch Size: {BATCH_SIZE_TRAIN * GRADIENT_ACCUMULATION_STEPS}\")\nprint(f\"Epochen: {NUM_EPOCHS}\")\nprint(f\"Labels: {len(ALL_LABELS)} Klassen\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFCRsEbLiomQ",
    "outputId": "d4a8b53c-422c-4d9f-bda8-e2d956bd2c27"
   },
   "outputs": [],
   "source": [
    "# ===== DATEN LADEN & CUSTOM SPLIT =====\n",
    "# Eigene Split-Logik: Test (fix pro Klasse), Rest -> Train/Val stratifiziert\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Datensatz laden\n",
    "ds = load_dataset(pu.DATASET_ID)\n",
    "\n",
    "# Train + Test kombinieren zu einem Gesamtpool\n",
    "train_hf = ds[\"train\"].to_pandas()\n",
    "test_hf = ds[\"test\"].to_pandas()\n",
    "all_labelled = pd.concat([train_hf, test_hf], ignore_index=True)\n",
    "\n",
    "print(f\"Gesamtpool gelabelter Artikel: {len(all_labelled)}\")\n",
    "print(f\"Klassen im Datensatz: {all_labelled['label'].nunique()}\")\n",
    "print()\n",
    "\n",
    "# --- Schritt 1: Test-Split (fix, stratifiziert) ---\n",
    "test_indices = []\n",
    "rest_indices = []\n",
    "\n",
    "for label in ALL_LABELS:\n",
    "    label_mask = all_labelled[\"label\"] == label\n",
    "    label_indices = all_labelled[label_mask].index.tolist()\n",
    "    n_total = len(label_indices)\n",
    "\n",
    "    if n_total < 60:\n",
    "        # Weniger als 60 Artikel -> Haelfte fuer Test\n",
    "        n_test = n_total // 2\n",
    "        print(f\"  {label}: nur {n_total} Artikel -> {n_test} fuer Test (Haelfte)\")\n",
    "    else:\n",
    "        n_test = TEST_PER_CLASS\n",
    "\n",
    "    np.random.shuffle(label_indices)\n",
    "    test_indices.extend(label_indices[:n_test])\n",
    "    rest_indices.extend(label_indices[n_test:])\n",
    "\n",
    "test_df = all_labelled.loc[test_indices].reset_index(drop=True)\n",
    "rest_df = all_labelled.loc[rest_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTest-Split: {len(test_df)} Artikel\")\n",
    "print(f\"Verbleibend fuer Train/Val: {len(rest_df)} Artikel\")\n",
    "\n",
    "# --- Schritt 2: Train/Validation-Split (stratifiziert) ---\n",
    "# Klassen mit <2 Artikeln komplett in Train\n",
    "class_counts = rest_df[\"label\"].value_counts()\n",
    "small_classes = class_counts[class_counts < 2].index.tolist()\n",
    "\n",
    "if small_classes:\n",
    "    print(f\"\\nKlassen mit <2 Artikeln (komplett in Train): {small_classes}\")\n",
    "    small_mask = rest_df[\"label\"].isin(small_classes)\n",
    "    train_small = rest_df[small_mask]\n",
    "    rest_for_split = rest_df[~small_mask]\n",
    "else:\n",
    "    train_small = pd.DataFrame(columns=rest_df.columns)\n",
    "    rest_for_split = rest_df\n",
    "\n",
    "train_main, val_df = train_test_split(\n",
    "    rest_for_split,\n",
    "    test_size=VAL_FRACTION,\n",
    "    stratify=rest_for_split[\"label\"],\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "train_df = pd.concat([train_main, train_small], ignore_index=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"  Train:      {len(train_df):>5} Artikel\")\n",
    "print(f\"  Validation: {len(val_df):>5} Artikel\")\n",
    "print(f\"  Test:       {len(test_df):>5} Artikel\")\n",
    "print(f\"  Gesamt:     {len(train_df) + len(val_df) + len(test_df):>5} Artikel\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Klassenverteilung\n",
    "split_overview = pd.DataFrame({\n",
    "    \"Train\": train_df[\"label\"].value_counts(),\n",
    "    \"Val\": val_df[\"label\"].value_counts(),\n",
    "    \"Test\": test_df[\"label\"].value_counts(),\n",
    "}).fillna(0).astype(int)\n",
    "split_overview[\"Gesamt\"] = split_overview.sum(axis=1)\n",
    "split_overview.loc[\"TOTAL\"] = split_overview.sum()\n",
    "print(\"\\nKlassenverteilung:\")\n",
    "print(split_overview.to_string())\n",
    "\n",
    "# Split-Config fuer Report\n",
    "split_config = {\n",
    "    \"dataset_id\": pu.DATASET_ID,\n",
    "    \"split_mode\": \"custom_finetune\",\n",
    "    \"test_per_class\": TEST_PER_CLASS,\n",
    "    \"val_fraction\": VAL_FRACTION,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"train_size\": len(train_df),\n",
    "    \"eval_size\": len(val_df),\n",
    "    \"test_size\": len(test_df),\n",
    "    \"raw_size\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVh0tLr_iomQ",
    "outputId": "470bb11a-a00b-4b2c-b407-ab4153aadeae"
   },
   "outputs": [],
   "source": [
    "# ===== LABEL ENCODING =====\n",
    "label2id = {label: idx for idx, label in enumerate(ALL_LABELS)}\n",
    "id2label = {idx: label for idx, label in enumerate(ALL_LABELS)}\n",
    "\n",
    "# Numerische label_id Spalte hinzufuegen\n",
    "train_df[\"label_id\"] = train_df[\"label\"].map(label2id)\n",
    "val_df[\"label_id\"] = val_df[\"label\"].map(label2id)\n",
    "test_df[\"label_id\"] = test_df[\"label\"].map(label2id)\n",
    "\n",
    "# Kontrolle: keine NaN-Labels\n",
    "for name, df in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
    "    n_missing = df[\"label_id\"].isna().sum()\n",
    "    if n_missing > 0:\n",
    "        print(f\"WARNUNG: {n_missing} unbekannte Labels in {name}!\")\n",
    "        print(df[df[\"label_id\"].isna()][\"label\"].unique())\n",
    "\n",
    "print(\"Label-Mapping:\")\n",
    "print(\"-\" * 40)\n",
    "for label, idx in label2id.items():\n",
    "    print(f\"  {idx:>2}: {label}\")\n",
    "print(f\"\\nAnzahl Klassen: {len(ALL_LABELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334,
     "referenced_widgets": [
      "de03a1f8651b4251a9d4cfdc669a5bda",
      "52d1baab22dc48a59c2d4dc450b8fc3e",
      "b2ab7356d32c4e4582ed4f2657cc6f63",
      "b886df1cbfb64e2c82e868d7697856fe",
      "80f8e0ae42b64269bd16c706d1f5437e",
      "e91cbc6c3a094acd8b260d7f42ad1c27",
      "acb328fa534c486e8c91ad731d82e1dd",
      "524aa20b684f48f497c34f1acfde60ee",
      "4c021dd64f224437905791bbccba92ae",
      "b8c344abc77d4783b9808ae08df082a5",
      "b3eca77390d14e33a41f5bd383a9059e",
      "024ab4959acd4c4aaafabc3c3b140e2c",
      "e4e19e3d917b4f3b97b106560371d698",
      "415b0b3ea8364145ab6ce6c46f95fa34",
      "8d8ccc366db245d283ce1f24725a45a4",
      "d33202f6f593483d9b7144d0b36c6020",
      "7be2e4dca7234a26bc4362a7e5223a65",
      "8c142e7aff594665bc48bbce67b6c223",
      "4d468f5b2ba94395ac21ac4fa07c6e9f",
      "b4501c32ebc346d9a4f518be811cddbc",
      "779bcc0157f54536bb4e627c04e8f95c",
      "1ab456e10b8047148d31ab576df214fd",
      "becd2272f4a4458098a980f9a94e3fe1",
      "26853dfd3b4041579e47c8daf66184fb",
      "71cc2bf958a54d02892d12d42c930f0d",
      "4890a92e4a05449c848315610a719e6c",
      "d1962591aad64d5f824934857a4daa17",
      "202b8d8b8b2e4c94b7e196112f4e4874",
      "d2336889698e4e4ba3d4364048859950",
      "6bb3318ef5484ffeb294246dbe01b344",
      "bcca90ffcc2e42dcbf8154991231340a",
      "94f89cb905654239bb53bb23b152cee0",
      "336a1f994ccb4c0d8261d2639e09a8a2"
     ]
    },
    "id": "FYivCtt8iomQ",
    "outputId": "d1355451-1a69-4b6f-8ec0-99fb0fd3d846"
   },
   "outputs": [],
   "source": [
    "# ===== TOKENISIERUNG =====\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "# DataFrames -> HuggingFace Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"}))\n",
    "val_dataset = Dataset.from_pandas(val_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"}))\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"}))\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        # Kein padding hier — wird dynamisch per DataCollatorWithPadding gemacht\n",
    "    )\n",
    "\n",
    "print(\"Tokenisiere Trainings-Daten...\")\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "print(\"Tokenisiere Validierungs-Daten...\")\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "print(\"Tokenisiere Test-Daten...\")\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Format setzen\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Beispiel-Tokenisierung\n",
    "example_text = train_df[\"text\"].iloc[0]\n",
    "example_tokens = tokenizer(example_text, max_length=MAX_LENGTH, truncation=True)\n",
    "print(f\"\\nBeispiel-Tokenisierung:\")\n",
    "print(f\"  Textlaenge (Zeichen): {len(example_text)}\")\n",
    "print(f\"  Token-Anzahl:         {len(example_tokens['input_ids'])}\")\n",
    "print(f\"  Max Length:           {MAX_LENGTH}\")\n",
    "print(f\"\\nDataset-Groessen:\")\n",
    "print(f\"  Train:      {len(train_dataset)}\")\n",
    "print(f\"  Validation: {len(val_dataset)}\")\n",
    "print(f\"  Test:       {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355,
     "referenced_widgets": [
      "b53f0174afed4a65b691a0e602595dc0",
      "d2e38c30801945daa1b688a94fae01e7",
      "fe9f8ab927fd4c41b5a892016004b4f5",
      "d3aebb5a0376457c91393de2294cc605",
      "63b9cb9887c54c3db7779accdfd7aac2",
      "0ee7edf611954e328f8b6bd5919ee998",
      "d76db361e2f14db0b76b8560895f008b",
      "83c9552945934002b81aa33c191b8a0f",
      "08f2e4d2522a44c8ab02acbb5fbcfa7e",
      "fa7ba846e5784c259a167020e7a8eb5e",
      "d77930d286c74bc294bacaa3dd2cebb6"
     ]
    },
    "id": "2qgvoaVDiomQ",
    "outputId": "8417dcc5-52ed-45c9-c4ee-c962caaa3cd4"
   },
   "outputs": [],
   "source": "# ===== MODELL INITIALISIEREN =====\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoConfig\n\n# EuroBERT-Fix: Das custom modeling_eurobert.py setzt rope_type=\"default\" wenn\n# config.rope_scaling null ist.\nfrom transformers.modeling_rope_utils import ROPE_INIT_FUNCTIONS\n\n# Wir definieren eine robuste default-Funktion, die fehlendes rope_theta handhabt.\n# Wir ueberschreiben \"default\" in jedem Fall, um sicherzustellen, dass\n# auch bei einem Re-Run der Zelle (nach Fehler) die korrigierte Version genutzt wird.\ndef _default_rope_init(config, device=None, **kwargs):\n    # Fix: rope_theta ist in EuroBertConfig nicht immer vorhanden -> Fallback auf 10000.0\n    base = getattr(config, \"rope_theta\", 10000.0)\n\n    # partial_rotary_factor existiert bei manchen Modellen\n    partial_rotary_factor = getattr(config, \"partial_rotary_factor\", 1.0)\n    head_dim = getattr(config, \"head_dim\", config.hidden_size // config.num_attention_heads)\n    dim = int(head_dim * partial_rotary_factor)\n    inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.int64).float().to(device) / dim))\n    return inv_freq, 1.0\n\nROPE_INIT_FUNCTIONS[\"default\"] = _default_rope_init\nprint(\"ROPE_INIT_FUNCTIONS gepatcht: 'default' gesetzt/aktualisiert.\")\n\n# Config laden (trust_remote_code fuer custom EuroBertConfig)\nconfig = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True)\nconfig.num_labels = len(ALL_LABELS)\nconfig.id2label = id2label\nconfig.label2id = label2id\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_ID,\n    config=config,\n    ignore_mismatched_sizes=True,\n    trust_remote_code=True,\n)\n\n# Parameter zaehlen\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nprint(f\"Modell: {MODEL_ID}\")\nprint(f\"Parameter gesamt:     {total_params:>12,}\")\nprint(f\"Parameter trainierbar:{trainable_params:>12,}\")\nprint(f\"Device: {device}\")\n\ngpu_info = pu.get_gpu_info()\nprint(f\"GPU: {gpu_info['gpu_name']} ({gpu_info['gpu_vram_gb']} GB)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlohdVKQiomQ",
    "outputId": "fb082646-e72d-4de3-dafe-dd3180382a90"
   },
   "outputs": [],
   "source": [
    "# ===== METRICS-FUNKTION =====\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Metriken fuer den Trainer: Accuracy, Balanced Accuracy, F1, Precision, Recall.\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "        \"precision_macro\": precision_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"precision_micro\": precision_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "        \"recall_macro\": recall_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"recall_micro\": recall_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "    }\n",
    "\n",
    "print(\"compute_metrics definiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufscbtOniomR",
    "outputId": "d6f7b596-405e-42ec-a273-2d54d7975173"
   },
   "outputs": [],
   "source": "# ===== TRAINER EINRICHTEN =====\nfrom transformers import TrainingArguments, Trainer, EarlyStoppingCallback, DataCollatorWithPadding\nimport torch\n\nOUTPUT_DIR = \"/content/eurobert_2_1b_finetune_output\"\n\n# Mixed Precision: BF16 fuer Ampere+ GPUs (L4, A100), FP16 fuer T4, keins fuer CPU\nuse_fp16 = False\nuse_bf16 = False\nif torch.cuda.is_available():\n    gpu_cap = torch.cuda.get_device_capability()\n    if gpu_cap[0] >= 8:  # Ampere oder neuer (L4, A100)\n        use_bf16 = True\n        print(f\"GPU Compute Capability {gpu_cap[0]}.{gpu_cap[1]} -> BF16 aktiviert\")\n    else:  # Aeltere GPUs (T4 = Compute Capability 7.5)\n        use_fp16 = True\n        print(f\"GPU Compute Capability {gpu_cap[0]}.{gpu_cap[1]} -> FP16 aktiviert\")\nelse:\n    print(\"WARNUNG: Keine GPU gefunden. Kein Mixed Precision moeglich.\")\n\n# Gradient Checkpointing auf CPU deaktivieren, da es dort zu XLA-Fehlern fuehren kann\nuse_grad_ckpt = torch.cuda.is_available()\n\n# Fused AdamW nur auf CUDA (schnellere Optimizer-Updates)\nuse_fused = torch.cuda.is_available()\noptim_name = \"adamw_torch_fused\" if use_fused else \"adamw_torch\"\n\n# WICHTIG: Sicherstellen, dass das Modell den Status uebernimmt (falls es vorher aktiviert war)\nif use_grad_ckpt:\n    model.gradient_checkpointing_enable()\nelse:\n    if hasattr(model, \"gradient_checkpointing_disable\"):\n        model.gradient_checkpointing_disable()\n    if hasattr(model, \"gradient_checkpointing\"):\n        model.gradient_checkpointing = False\n\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    num_train_epochs=NUM_EPOCHS,\n    learning_rate=LEARNING_RATE,\n    per_device_train_batch_size=BATCH_SIZE_TRAIN,\n    per_device_eval_batch_size=BATCH_SIZE_EVAL,\n    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n    warmup_ratio=WARMUP_RATIO,\n    weight_decay=WEIGHT_DECAY,\n    fp16=use_fp16,\n    bf16=use_bf16,\n    gradient_checkpointing=use_grad_ckpt,\n    optim=optim_name,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=50,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1_macro\",\n    greater_is_better=True,\n    save_total_limit=3,\n    report_to=\"none\",\n    seed=RANDOM_SEED,\n    dataloader_num_workers=4 if torch.cuda.is_available() else 0,\n    dataloader_pin_memory=torch.cuda.is_available(),\n)\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n)\n\nprint(\"\\nTrainer konfiguriert.\")\nprint(f\"  Output:     {OUTPUT_DIR}\")\nprint(f\"  Epochen:    {NUM_EPOCHS}\")\nprint(f\"  LR:         {LEARNING_RATE}\")\nprint(f\"  Batch Size: {BATCH_SIZE_TRAIN} x {GRADIENT_ACCUMULATION_STEPS} = {BATCH_SIZE_TRAIN * GRADIENT_ACCUMULATION_STEPS} effektiv\")\nprint(f\"  Early Stop: patience=2, metric=f1_macro\")\nprint(f\"  Gradient Checkpointing: {use_grad_ckpt}\")\nprint(f\"  FP16: {use_fp16} | BF16: {use_bf16}\")\nprint(f\"  Optimizer:  {optim_name}\")\nprint(f\"  DataLoader Workers: {training_args.dataloader_num_workers}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "Qj93nMHfiomR",
    "outputId": "dd2ae465-a0d9-4c91-8248-1213ff1fc2cd"
   },
   "outputs": [],
   "source": [
    "# ===== TRAINING STARTEN =====\n",
    "timer = pu.ExperimentTimer()\n",
    "with timer:\n",
    "    train_result = trainer.train()\n",
    "\n",
    "print(f\"\\nTraining abgeschlossen: {timer.duration_formatted}\")\n",
    "print(f\"\\nTraining-Metriken:\")\n",
    "for key, val in train_result.metrics.items():\n",
    "    print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gz9vSfxgiomR"
   },
   "outputs": [],
   "source": "# ===== TRAINING-VERLAUF PLOTTEN =====\nimport matplotlib.pyplot as plt\n\nlog_history = trainer.state.log_history\n\n# Training Loss extrahieren (aus den Step-Logs)\ntrain_steps = [e[\"step\"] for e in log_history if \"loss\" in e]\ntrain_losses = [e[\"loss\"] for e in log_history if \"loss\" in e]\n\n# Eval-Metriken extrahieren (aus den Epoch-Logs)\neval_logs = [e for e in log_history if \"eval_loss\" in e]\neval_epochs = [e[\"epoch\"] for e in eval_logs]\neval_losses = [e[\"eval_loss\"] for e in eval_logs]\neval_f1_macro = [e.get(\"eval_f1_macro\", 0) for e in eval_logs]\neval_accuracy = [e.get(\"eval_accuracy\", 0) for e in eval_logs]\neval_balanced_acc = [e.get(\"eval_balanced_accuracy\", 0) for e in eval_logs]\neval_precision_macro = [e.get(\"eval_precision_macro\", 0) for e in eval_logs]\neval_recall_macro = [e.get(\"eval_recall_macro\", 0) for e in eval_logs]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n\n# Plot 1: Loss\nax1.plot(train_steps, train_losses, alpha=0.4, label=\"Train Loss (Steps)\", color=\"steelblue\")\n# Eval Loss auf der Step-Achse (am Ende jeder Epoch)\neval_steps_approx = [e.get(\"step\", 0) for e in eval_logs]\nax1.plot(eval_steps_approx, eval_losses, \"o-\", label=\"Eval Loss (Epoch)\", color=\"orangered\", linewidth=2)\nax1.set_xlabel(\"Steps\")\nax1.set_ylabel(\"Loss\")\nax1.set_title(\"Training vs. Eval Loss\")\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Eval-Metriken ueber Epochen\nax2.plot(eval_epochs, eval_f1_macro, \"o-\", label=\"F1 Macro\", linewidth=2)\nax2.plot(eval_epochs, eval_accuracy, \"s-\", label=\"Accuracy\", linewidth=2)\nax2.plot(eval_epochs, eval_balanced_acc, \"^-\", label=\"Balanced Accuracy\", linewidth=2)\nax2.plot(eval_epochs, eval_precision_macro, \"d-\", label=\"Precision Macro\", linewidth=1.5, alpha=0.7)\nax2.plot(eval_epochs, eval_recall_macro, \"v-\", label=\"Recall Macro\", linewidth=1.5, alpha=0.7)\nax2.set_xlabel(\"Epoch\")\nax2.set_ylabel(\"Score\")\nax2.set_title(\"Eval-Metriken pro Epoch\")\nax2.legend(loc=\"lower right\")\nax2.grid(True, alpha=0.3)\nax2.set_ylim(0, 1)\n\nplt.suptitle(\"EuroBERT-2.1B Fine-Tuning Verlauf\", fontsize=14, fontweight=\"bold\")\nplt.tight_layout()\nplt.show()\n\n# Tabellarisch\nprint(\"\\nEval-Metriken pro Epoch:\")\nprint(f\"{'Epoch':>6} {'Loss':>8} {'F1 Macro':>10} {'Accuracy':>10} {'Bal. Acc.':>10}\")\nprint(\"-\" * 50)\nfor log in eval_logs:\n    print(f\"{log['epoch']:>6.0f} {log['eval_loss']:>8.4f} {log.get('eval_f1_macro', 0):>10.4f} {log.get('eval_accuracy', 0):>10.4f} {log.get('eval_balanced_accuracy', 0):>10.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfBOXzakiomR"
   },
   "outputs": [],
   "source": "# ===== EVALUATION AUF TEST-SET =====\nprint(\"Evaluation auf Test-Set mit bestem Modell...\")\n\ntest_preds = trainer.predict(test_dataset)\npred_ids = np.argmax(test_preds.predictions, axis=-1)\npred_labels = [id2label[i] for i in pred_ids]\ntrue_labels = [id2label[i] for i in test_preds.label_ids]\n\n# Standardisierte Evaluation mit pipeline_utils\nmetrics = pu.evaluate(\n    true_labels,\n    pred_labels,\n    labels=ALL_LABELS,\n    experiment_name=\"test\",\n)\npu.print_metrics(metrics, \"Fine-Tuned EuroBERT-2.1B — Test Split\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuIOhO3UiomR"
   },
   "outputs": [],
   "source": "# ===== CONFUSION MATRIX =====\npu.plot_confusion_matrix(\n    metrics,\n    title=\"Fine-Tuned EuroBERT-2.1B (Test)\",\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okXdEsaXiomR"
   },
   "outputs": [],
   "source": "# ===== PER-CLASS METRICS BARPLOT =====\nimport matplotlib.pyplot as plt\nimport numpy as np\n\npc_df = metrics[\"per_class_df\"].copy()\npc_df = pc_df.sort_values(\"F1\", ascending=True)\n\nfig, ax = plt.subplots(figsize=(12, 8))\n\ny_pos = np.arange(len(pc_df))\nbar_height = 0.25\n\nax.barh(y_pos - bar_height, pc_df[\"Precision\"], bar_height, label=\"Precision\", color=\"#2196F3\", alpha=0.85)\nax.barh(y_pos, pc_df[\"Recall\"], bar_height, label=\"Recall\", color=\"#FF9800\", alpha=0.85)\nax.barh(y_pos + bar_height, pc_df[\"F1\"], bar_height, label=\"F1\", color=\"#4CAF50\", alpha=0.85)\n\nax.set_yticks(y_pos)\nax.set_yticklabels(pc_df[\"Label\"])\nax.set_xlabel(\"Score\")\nax.set_title(\"Per-Class Metrics: Fine-Tuned EuroBERT-2.1B\", fontsize=13, fontweight=\"bold\")\nax.legend(loc=\"lower right\")\nax.set_xlim(0, 1.05)\nax.grid(axis=\"x\", alpha=0.3)\n\n# F1-Werte als Text\nfor i, (_, row) in enumerate(pc_df.iterrows()):\n    ax.text(row[\"F1\"] + 0.01, y_pos[i] + bar_height, f\"{row['F1']:.2f}\", va=\"center\", fontsize=9)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OpORbByyiomR"
   },
   "outputs": [],
   "source": "# ===== REPORT GENERIEREN =====\n\n# Training-Parameter fuer Report\ntraining_params = {\n    \"num_epochs\": NUM_EPOCHS,\n    \"learning_rate\": LEARNING_RATE,\n    \"batch_size_train\": BATCH_SIZE_TRAIN,\n    \"batch_size_eval\": BATCH_SIZE_EVAL,\n    \"gradient_accumulation_steps\": GRADIENT_ACCUMULATION_STEPS,\n    \"effective_batch_size\": BATCH_SIZE_TRAIN * GRADIENT_ACCUMULATION_STEPS,\n    \"warmup_ratio\": WARMUP_RATIO,\n    \"weight_decay\": WEIGHT_DECAY,\n    \"max_length\": MAX_LENGTH,\n    \"fp16\": FP16,\n    \"early_stopping_patience\": 2,\n    \"best_checkpoint\": trainer.state.best_model_checkpoint,\n    \"best_metric\": round(trainer.state.best_metric, 4) if trainer.state.best_metric else None,\n}\n\n# Model-Config manuell extrahieren (extract_model_config erwartet Pipeline-Objekt)\nconfig_dict = model.config.to_dict()\nmodel_config = {}\nfor field in [\"architectures\", \"model_type\", \"hidden_size\", \"num_hidden_layers\",\n              \"num_attention_heads\", \"vocab_size\", \"max_position_embeddings\"]:\n    if field in config_dict:\n        val = config_dict[field]\n        if field == \"architectures\" and isinstance(val, list):\n            val = val[0] if len(val) == 1 else \", \".join(val)\n        model_config[field] = val\n\nreport_path = pu.generate_report(\n    model_name=f\"{MODEL_SHORT_NAME}_finetune\",\n    model_type=MODEL_TYPE,\n    metrics=metrics,\n    timer=timer,\n    model_info=MODEL_INFO,\n    candidate_labels=ALL_LABELS,\n    hypothesis_template=None,\n    split_config=split_config,\n    label_mapping={l: l for l in ALL_LABELS},\n    model_config=model_config,\n    training_params=training_params,\n    experiment_notes=(\n        f\"Fine-Tuned EuroBERT-2.1B auf {len(train_df)} Trainingsartikeln. \"\n        f\"Max Length {MAX_LENGTH}, FP16, EarlyStoppingCallback(patience=2). \"\n        f\"Custom Split: {TEST_PER_CLASS} Test/Klasse, Rest 80/20 Train/Val.\"\n    ),\n)\n\nprint(f\"\\nReport gespeichert: {report_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37KDD3T5iomR"
   },
   "outputs": [],
   "source": "# ===== MODELL AUF HUGGINGFACE HOCHLADEN (optional) =====\nUPLOAD = False  # auf True setzen zum Hochladen\n\nif UPLOAD:\n    REPO_NAME = \"Zorryy/eurobert-2-1b-news-classifier-v1\"\n    url = pu.upload_model_to_hub(\n        model=trainer.model,\n        tokenizer=tokenizer,\n        repo_name=REPO_NAME,\n        private=True,\n        training_params=training_params,\n    )\n    print(f\"Model uploaded: {url}\")\nelse:\n    print(\"Upload uebersprungen (UPLOAD = False).\")\n    print(\"Setze UPLOAD = True und fuehre die Zelle erneut aus, um das Modell hochzuladen.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d54Elq4xiomS"
   },
   "outputs": [],
   "source": [
    "# ===== SUMMARY =====\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Model:           {MODEL_ID}\")\n",
    "print(f\"  Type:            {MODEL_TYPE}\")\n",
    "print(f\"  Train:           {len(train_df)} Artikel\")\n",
    "print(f\"  Validation:      {len(val_df)} Artikel\")\n",
    "print(f\"  Test:            {len(test_df)} Artikel\")\n",
    "print(f\"  Epochen:         {NUM_EPOCHS} (best: {trainer.state.best_model_checkpoint})\")\n",
    "print(f\"  F1 Macro:        {metrics['f1_macro']:.4f}\")\n",
    "print(f\"  F1 Weighted:     {metrics['f1_weighted']:.4f}\")\n",
    "print(f\"  Accuracy:        {metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision Macro: {metrics['precision_macro']:.4f}\")\n",
    "print(f\"  Recall Macro:    {metrics['recall_macro']:.4f}\")\n",
    "print(f\"  Dauer:           {timer.duration_formatted}\")\n",
    "print(f\"  Report:          {report_path}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}