{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning: newsBERT_euro_210m\n",
    "## EuroBERT-210M mit optimierten HPT-Parametern\n",
    "\n",
    "Trainiert EuroBERT-210M mit den besten Hyperparametern aus Phase 1 HPT\n",
    "und pusht das Modell als `Zorryy/newsBERT_euro_210m` auf HuggingFace.\n",
    "\n",
    "**Voraussetzung:** GPU-Runtime (L4 empfohlen), `HF_TOKEN` in Colab Secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETUP ===\n",
    "import os, sys\n",
    "\n",
    "REPO = \"/content/news_articles_classification_thesis\"\n",
    "if not os.path.exists(REPO):\n",
    "    !git clone https://github.com/ZorbeyOezcan/news_articles_classification_thesis.git {REPO}\n",
    "else:\n",
    "    !cd {REPO} && git pull -q\n",
    "\n",
    "!pip install -q transformers[sentencepiece] datasets huggingface_hub \\\n",
    "    scikit-learn matplotlib seaborn tqdm pandas accelerate evaluate\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=False)\n",
    "\n",
    "PIPELINE_DIR = f\"{REPO}/Python/classification_pipeline\"\n",
    "if PIPELINE_DIR not in sys.path:\n",
    "    sys.path.insert(0, PIPELINE_DIR)\n",
    "\n",
    "import importlib\n",
    "import pipeline_utils as pu\n",
    "importlib.reload(pu)\n",
    "\n",
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "login(token=userdata.get(\"HF_TOKEN\"))\n",
    "\n",
    "print(f\"Reports-Ordner: {pu.REPORTS_DIR}\")\n",
    "print(\"Setup abgeschlossen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL & HPT CONFIG ===\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "MODEL_ID = \"EuroBERT/EuroBERT-210m\"\n",
    "MODEL_SHORT_NAME = \"newsBERT_euro_210m\"\n",
    "MODEL_TYPE = \"fine-tuned\"\n",
    "REPO_NAME = \"Zorryy/newsBERT_euro_210m\"  # HuggingFace Repo\n",
    "\n",
    "# ----- Beste HPT-Parameter (Phase 1) -----\n",
    "LEARNING_RATE = 3.76e-05\n",
    "LR_SCHEDULER_TYPE = \"linear\"\n",
    "NUM_EPOCHS = 13\n",
    "BATCH_SIZE_TRAIN = 4\n",
    "WARMUP_RATIO = 0.0880168\n",
    "WEIGHT_DECAY = 0.0439249\n",
    "LABEL_SMOOTHING = 0.0320202\n",
    "\n",
    "# ----- Feste Parameter -----\n",
    "MAX_LENGTH = 2048\n",
    "EFFECTIVE_BATCH_SIZE = 16\n",
    "GRADIENT_ACCUMULATION_STEPS = EFFECTIVE_BATCH_SIZE // BATCH_SIZE_TRAIN  # = 4\n",
    "RANDOM_SEED = 42\n",
    "TEST_PER_CLASS = 30\n",
    "VAL_FRACTION = 0.2\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "\n",
    "# ----- GPU-adaptive Einstellungen -----\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"GPU benoetigt! Bitte Colab Runtime aendern.\")\n",
    "\n",
    "_gpu_cap = torch.cuda.get_device_capability()\n",
    "_gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "\n",
    "if _gpu_cap[0] >= 8:  # Ampere+ (L4, A100)\n",
    "    USE_BF16 = True\n",
    "    USE_FP16 = False\n",
    "else:  # T4\n",
    "    USE_BF16 = False\n",
    "    USE_FP16 = True\n",
    "\n",
    "if _gpu_mem >= 40:\n",
    "    BATCH_SIZE_EVAL = 32\n",
    "elif _gpu_mem >= 20:\n",
    "    BATCH_SIZE_EVAL = 16\n",
    "else:\n",
    "    BATCH_SIZE_EVAL = 8\n",
    "\n",
    "OPTIM = \"adamw_torch_fused\"\n",
    "\n",
    "# Labels\n",
    "ALL_LABELS = [\n",
    "    \"Klima / Energie\", \"Zuwanderung\", \"Renten\", \"Soziales Gef\\u00e4lle\",\n",
    "    \"AfD/Rechte\", \"Arbeitslosigkeit\", \"Wirtschaftslage\", \"Politikverdruss\",\n",
    "    \"Gesundheitswesen, Pflege\", \"Kosten/L\\u00f6hne/Preise\",\n",
    "    \"Ukraine/Krieg/Russland\", \"Bundeswehr/Verteidigung\", \"Andere\",\n",
    "]\n",
    "\n",
    "MODEL_INFO = {\n",
    "    \"huggingface_id\": MODEL_ID,\n",
    "    \"language\": \"Multilingual (inkl. Deutsch)\",\n",
    "    \"max_tokens\": MAX_LENGTH,\n",
    "    \"parameters\": \"210M\",\n",
    "    \"notes\": \"EuroBERT-210m fine-tuned mit HPT-optimierten Parametern. Pushed als newsBERT_euro_210m.\",\n",
    "}\n",
    "\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)} ({_gpu_mem:.1f} GB, CC {_gpu_cap[0]}.{_gpu_cap[1]})\")\n",
    "print(f\"  BF16={USE_BF16}, FP16={USE_FP16}, Eval Batch={BATCH_SIZE_EVAL}\")\n",
    "print(f\"\\nHPT-Parameter:\")\n",
    "print(f\"  LR:              {LEARNING_RATE}\")\n",
    "print(f\"  Scheduler:       {LR_SCHEDULER_TYPE}\")\n",
    "print(f\"  Epochs:          {NUM_EPOCHS}\")\n",
    "print(f\"  Batch (train):   {BATCH_SIZE_TRAIN}\")\n",
    "print(f\"  Grad Accum:      {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"  Effektive BS:    {EFFECTIVE_BATCH_SIZE}\")\n",
    "print(f\"  Warmup Ratio:    {WARMUP_RATIO}\")\n",
    "print(f\"  Weight Decay:    {WEIGHT_DECAY}\")\n",
    "print(f\"  Label Smoothing: {LABEL_SMOOTHING}\")\n",
    "print(f\"  Early Stopping:  patience={EARLY_STOPPING_PATIENCE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATEN LADEN & CUSTOM SPLIT ===\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "ds = load_dataset(pu.DATASET_ID)\n",
    "train_hf = ds[\"train\"].to_pandas()\n",
    "test_hf = ds[\"test\"].to_pandas()\n",
    "all_labelled = pd.concat([train_hf, test_hf], ignore_index=True)\n",
    "\n",
    "print(f\"Gesamtpool gelabelter Artikel: {len(all_labelled)}\")\n",
    "print(f\"Klassen: {all_labelled['label'].nunique()}\\n\")\n",
    "\n",
    "# Test-Split (fix, stratifiziert)\n",
    "test_indices = []\n",
    "rest_indices = []\n",
    "\n",
    "for label in ALL_LABELS:\n",
    "    label_mask = all_labelled[\"label\"] == label\n",
    "    label_indices = all_labelled[label_mask].index.tolist()\n",
    "    n_total = len(label_indices)\n",
    "\n",
    "    if n_total < 60:\n",
    "        n_test = n_total // 2\n",
    "        print(f\"  {label}: nur {n_total} Artikel -> {n_test} fuer Test\")\n",
    "    else:\n",
    "        n_test = TEST_PER_CLASS\n",
    "\n",
    "    np.random.shuffle(label_indices)\n",
    "    test_indices.extend(label_indices[:n_test])\n",
    "    rest_indices.extend(label_indices[n_test:])\n",
    "\n",
    "test_df = all_labelled.loc[test_indices].reset_index(drop=True)\n",
    "rest_df = all_labelled.loc[rest_indices].reset_index(drop=True)\n",
    "\n",
    "# Train/Val Split (stratifiziert)\n",
    "class_counts = rest_df[\"label\"].value_counts()\n",
    "small_classes = class_counts[class_counts < 2].index.tolist()\n",
    "\n",
    "if small_classes:\n",
    "    small_mask = rest_df[\"label\"].isin(small_classes)\n",
    "    train_small = rest_df[small_mask]\n",
    "    rest_for_split = rest_df[~small_mask]\n",
    "else:\n",
    "    train_small = pd.DataFrame(columns=rest_df.columns)\n",
    "    rest_for_split = rest_df\n",
    "\n",
    "train_main, val_df = train_test_split(\n",
    "    rest_for_split, test_size=VAL_FRACTION,\n",
    "    stratify=rest_for_split[\"label\"], random_state=RANDOM_SEED,\n",
    ")\n",
    "train_df = pd.concat([train_main, train_small], ignore_index=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"  Train:      {len(train_df):>5}\")\n",
    "print(f\"  Validation: {len(val_df):>5}\")\n",
    "print(f\"  Test:       {len(test_df):>5}\")\n",
    "print(f\"  Gesamt:     {len(train_df) + len(val_df) + len(test_df):>5}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "split_config = {\n",
    "    \"dataset_id\": pu.DATASET_ID,\n",
    "    \"split_mode\": \"custom_finetune\",\n",
    "    \"test_per_class\": TEST_PER_CLASS,\n",
    "    \"val_fraction\": VAL_FRACTION,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"train_size\": len(train_df),\n",
    "    \"eval_size\": len(val_df),\n",
    "    \"test_size\": len(test_df),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LABEL ENCODING ===\n",
    "label2id = {label: idx for idx, label in enumerate(ALL_LABELS)}\n",
    "id2label = {idx: label for idx, label in enumerate(ALL_LABELS)}\n",
    "\n",
    "train_df[\"label_id\"] = train_df[\"label\"].map(label2id)\n",
    "val_df[\"label_id\"] = val_df[\"label\"].map(label2id)\n",
    "test_df[\"label_id\"] = test_df[\"label\"].map(label2id)\n",
    "\n",
    "for name, _df in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
    "    assert _df[\"label_id\"].isna().sum() == 0, f\"Unbekannte Labels in {name}!\"\n",
    "\n",
    "print(\"Label-Mapping:\")\n",
    "for label, idx in label2id.items():\n",
    "    print(f\"  {idx:>2}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TOKENISIERUNG ===\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(examples[\"text\"], max_length=MAX_LENGTH, truncation=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"}))\n",
    "val_dataset = Dataset.from_pandas(val_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"}))\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"}))\n",
    "\n",
    "print(\"Tokenisiere...\")\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODELL INITIALISIEREN ===\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers.modeling_rope_utils import ROPE_INIT_FUNCTIONS\n",
    "\n",
    "# EuroBERT RoPE Fix\n",
    "def _default_rope_init(config, device=None, **kwargs):\n",
    "    base = getattr(config, \"rope_theta\", 10000.0)\n",
    "    partial_rotary_factor = getattr(config, \"partial_rotary_factor\", 1.0)\n",
    "    head_dim = getattr(config, \"head_dim\", config.hidden_size // config.num_attention_heads)\n",
    "    dim = int(head_dim * partial_rotary_factor)\n",
    "    inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.int64).float().to(device) / dim))\n",
    "    return inv_freq, 1.0\n",
    "\n",
    "ROPE_INIT_FUNCTIONS[\"default\"] = _default_rope_init\n",
    "\n",
    "# Modell laden\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "config.num_labels = len(ALL_LABELS)\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID, config=config,\n",
    "    ignore_mismatched_sizes=True, trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Classifier Head stabilisieren (kleinere Init -> verhindert Logit-Overflow in BF16)\n",
    "for name, module in model.named_modules():\n",
    "    if name in (\"dense\", \"classifier\") and isinstance(module, nn.Linear):\n",
    "        nn.init.normal_(module.weight, mean=0.0, std=0.002)\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Modell: {MODEL_ID}\")\n",
    "print(f\"Parameter: {total_params:,}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"GPU: {pu.get_gpu_info()['gpu_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === METRICS ===\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score,\n",
    "    f1_score, precision_score, recall_score,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\", zero_division=0),\n",
    "        \"precision_macro\": precision_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"recall_macro\": recall_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "    }\n",
    "\n",
    "print(\"compute_metrics definiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAINER ===\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback, DataCollatorWithPadding\n",
    "\n",
    "OUTPUT_DIR = \"/content/newsbert_finetune_output\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
    "    per_device_train_batch_size=BATCH_SIZE_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_SIZE_EVAL,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    label_smoothing_factor=LABEL_SMOOTHING,\n",
    "    fp16=USE_FP16,\n",
    "    bf16=USE_BF16,\n",
    "    gradient_checkpointing=False,  # EuroBERT custom modeling: loss=0 mit grad ckpt\n",
    "    optim=OPTIM,\n",
    "    group_by_length=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=25,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=3,\n",
    "    report_to=\"none\",\n",
    "    seed=RANDOM_SEED,\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE)],\n",
    ")\n",
    "\n",
    "print(\"Trainer konfiguriert.\")\n",
    "print(f\"  Epochs:       {NUM_EPOCHS}\")\n",
    "print(f\"  LR:           {LEARNING_RATE} ({LR_SCHEDULER_TYPE})\")\n",
    "print(f\"  Batch:        {BATCH_SIZE_TRAIN} x {GRADIENT_ACCUMULATION_STEPS} = {EFFECTIVE_BATCH_SIZE} effektiv\")\n",
    "print(f\"  Warmup:       {WARMUP_RATIO}\")\n",
    "print(f\"  Weight Decay: {WEIGHT_DECAY}\")\n",
    "print(f\"  Label Smooth: {LABEL_SMOOTHING}\")\n",
    "print(f\"  BF16={USE_BF16}, FP16={USE_FP16}\")\n",
    "print(f\"  Early Stop:   patience={EARLY_STOPPING_PATIENCE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAINING ===\n",
    "timer = pu.ExperimentTimer()\n",
    "with timer:\n",
    "    train_result = trainer.train()\n",
    "\n",
    "print(f\"\\nTraining abgeschlossen: {timer.duration_formatted}\")\n",
    "print(f\"\\nTraining-Metriken:\")\n",
    "for key, val in train_result.metrics.items():\n",
    "    print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAINING-VERLAUF ===\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "train_steps = [e[\"step\"] for e in log_history if \"loss\" in e]\n",
    "train_losses = [e[\"loss\"] for e in log_history if \"loss\" in e]\n",
    "\n",
    "eval_logs = [e for e in log_history if \"eval_loss\" in e]\n",
    "eval_epochs = [e[\"epoch\"] for e in eval_logs]\n",
    "eval_losses = [e[\"eval_loss\"] for e in eval_logs]\n",
    "eval_f1 = [e.get(\"eval_f1_macro\", 0) for e in eval_logs]\n",
    "eval_acc = [e.get(\"eval_accuracy\", 0) for e in eval_logs]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "ax1.plot(train_steps, train_losses, alpha=0.4, label=\"Train Loss\", color=\"steelblue\")\n",
    "eval_steps = [e.get(\"step\", 0) for e in eval_logs]\n",
    "ax1.plot(eval_steps, eval_losses, \"o-\", label=\"Eval Loss\", color=\"orangered\", linewidth=2)\n",
    "ax1.set_xlabel(\"Steps\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Training vs. Eval Loss\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(eval_epochs, eval_f1, \"o-\", label=\"F1 Macro\", linewidth=2)\n",
    "ax2.plot(eval_epochs, eval_acc, \"s-\", label=\"Accuracy\", linewidth=2)\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Score\")\n",
    "ax2.set_title(\"Eval-Metriken pro Epoch\")\n",
    "ax2.legend(loc=\"lower right\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle(\"newsBERT_euro_210m Fine-Tuning Verlauf\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEval-Metriken pro Epoch:\")\n",
    "print(f\"{'Epoch':>6} {'Loss':>8} {'F1 Macro':>10} {'Accuracy':>10}\")\n",
    "print(\"-\" * 40)\n",
    "for log in eval_logs:\n",
    "    print(f\"{log['epoch']:>6.0f} {log['eval_loss']:>8.4f} {log.get('eval_f1_macro', 0):>10.4f} {log.get('eval_accuracy', 0):>10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EVALUATION AUF TEST-SET ===\n",
    "print(\"Evaluation auf Test-Set mit bestem Modell...\")\n",
    "\n",
    "test_preds = trainer.predict(test_dataset)\n",
    "pred_ids = np.argmax(test_preds.predictions, axis=-1)\n",
    "pred_labels = [id2label[i] for i in pred_ids]\n",
    "true_labels = [id2label[i] for i in test_preds.label_ids]\n",
    "\n",
    "metrics = pu.evaluate(\n",
    "    true_labels, pred_labels,\n",
    "    labels=ALL_LABELS, experiment_name=\"test\",\n",
    ")\n",
    "pu.print_metrics(metrics, \"newsBERT_euro_210m â€” Test Split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFUSION MATRIX ===\n",
    "pu.plot_confusion_matrix(metrics, title=\"newsBERT_euro_210m (Test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PER-CLASS METRICS ===\n",
    "pc_df = metrics[\"per_class_df\"].copy().sort_values(\"F1\", ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "y_pos = np.arange(len(pc_df))\n",
    "bar_h = 0.25\n",
    "\n",
    "ax.barh(y_pos - bar_h, pc_df[\"Precision\"], bar_h, label=\"Precision\", color=\"#2196F3\", alpha=0.85)\n",
    "ax.barh(y_pos, pc_df[\"Recall\"], bar_h, label=\"Recall\", color=\"#FF9800\", alpha=0.85)\n",
    "ax.barh(y_pos + bar_h, pc_df[\"F1\"], bar_h, label=\"F1\", color=\"#4CAF50\", alpha=0.85)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(pc_df[\"Label\"])\n",
    "ax.set_xlabel(\"Score\")\n",
    "ax.set_title(\"Per-Class Metrics: newsBERT_euro_210m\", fontsize=13, fontweight=\"bold\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.set_xlim(0, 1.05)\n",
    "ax.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "for i, (_, row) in enumerate(pc_df.iterrows()):\n",
    "    ax.text(row[\"F1\"] + 0.01, y_pos[i] + bar_h, f\"{row['F1']:.2f}\", va=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === REPORT ===\n",
    "training_params = {\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"lr_scheduler_type\": LR_SCHEDULER_TYPE,\n",
    "    \"batch_size_train\": BATCH_SIZE_TRAIN,\n",
    "    \"batch_size_eval\": BATCH_SIZE_EVAL,\n",
    "    \"gradient_accumulation_steps\": GRADIENT_ACCUMULATION_STEPS,\n",
    "    \"effective_batch_size\": EFFECTIVE_BATCH_SIZE,\n",
    "    \"warmup_ratio\": WARMUP_RATIO,\n",
    "    \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"label_smoothing_factor\": LABEL_SMOOTHING,\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"bf16\": USE_BF16,\n",
    "    \"fp16\": USE_FP16,\n",
    "    \"early_stopping_patience\": EARLY_STOPPING_PATIENCE,\n",
    "    \"best_checkpoint\": trainer.state.best_model_checkpoint,\n",
    "    \"best_metric\": round(trainer.state.best_metric, 4) if trainer.state.best_metric else None,\n",
    "}\n",
    "\n",
    "config_dict = model.config.to_dict()\n",
    "model_config = {}\n",
    "for field in [\"architectures\", \"model_type\", \"hidden_size\", \"num_hidden_layers\",\n",
    "              \"num_attention_heads\", \"vocab_size\", \"max_position_embeddings\"]:\n",
    "    if field in config_dict:\n",
    "        val = config_dict[field]\n",
    "        if field == \"architectures\" and isinstance(val, list):\n",
    "            val = val[0] if len(val) == 1 else \", \".join(val)\n",
    "        model_config[field] = val\n",
    "\n",
    "report_path = pu.generate_report(\n",
    "    model_name=MODEL_SHORT_NAME,\n",
    "    model_type=MODEL_TYPE,\n",
    "    metrics=metrics,\n",
    "    timer=timer,\n",
    "    model_info=MODEL_INFO,\n",
    "    candidate_labels=ALL_LABELS,\n",
    "    split_config=split_config,\n",
    "    label_mapping={l: l for l in ALL_LABELS},\n",
    "    model_config=model_config,\n",
    "    training_params=training_params,\n",
    "    experiment_notes=(\n",
    "        f\"newsBERT_euro_210m: EuroBERT-210M fine-tuned mit HPT-optimierten Parametern. \"\n",
    "        f\"LR={LEARNING_RATE}, Epochs={NUM_EPOCHS}, Label Smoothing={LABEL_SMOOTHING}. \"\n",
    "        f\"Custom Split: {TEST_PER_CLASS} Test/Klasse, Rest {int((1-VAL_FRACTION)*100)}/{int(VAL_FRACTION*100)} Train/Val.\"\n",
    "    ),\n",
    ")\n",
    "print(f\"Report gespeichert: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODELL AUF HUGGINGFACE PUSHEN ===\n",
    "url = pu.upload_model_to_hub(\n",
    "    model=trainer.model,\n",
    "    tokenizer=tokenizer,\n",
    "    repo_name=REPO_NAME,\n",
    "    private=True,\n",
    "    training_params=training_params,\n",
    ")\n",
    "print(f\"\\nModell hochgeladen: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SUMMARY ===\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Model:           {REPO_NAME}\")\n",
    "print(f\"  Base:            {MODEL_ID}\")\n",
    "print(f\"  Train:           {len(train_df)} Artikel\")\n",
    "print(f\"  Validation:      {len(val_df)} Artikel\")\n",
    "print(f\"  Test:            {len(test_df)} Artikel\")\n",
    "print(f\"  Epochs:          {NUM_EPOCHS} (best: {trainer.state.best_model_checkpoint})\")\n",
    "print(f\"  F1 Macro:        {metrics['f1_macro']:.4f}\")\n",
    "print(f\"  F1 Weighted:     {metrics['f1_weighted']:.4f}\")\n",
    "print(f\"  Accuracy:        {metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision Macro: {metrics['precision_macro']:.4f}\")\n",
    "print(f\"  Recall Macro:    {metrics['recall_macro']:.4f}\")\n",
    "print(f\"  Dauer:           {timer.duration_formatted}\")\n",
    "print(f\"  Report:          {report_path}\")\n",
    "print(f\"  HuggingFace:     {url}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLEANUP ===\n",
    "import gc, shutil\n",
    "\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "    print(\"Checkpoint-Dateien geloescht.\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    free_mem = torch.cuda.mem_get_info()[0] / 1e9\n",
    "    print(f\"GPU VRAM frei: {free_mem:.1f} GB\")\n",
    "\n",
    "print(\"\\nFertig. Runtime kann beendet werden.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}