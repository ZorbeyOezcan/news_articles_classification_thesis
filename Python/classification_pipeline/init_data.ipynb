{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Data\n",
    "\n",
    "Lädt den Datensatz von HuggingFace und erstellt Train/Eval/Test Splits.\n",
    "Nach Ausführung sind die Daten für alle `classify_*.ipynb` Notebooks verfügbar.\n",
    "\n",
    "**Voraussetzung:** `init_colab.ipynb` muss vorher ausgeführt worden sein."
   ]
  },
  {
   "cell_type": "code",
   "source": "# Pfad setzen (falls nicht über init_colab geladen)\nimport sys\nPIPELINE_DIR = \"/content/news_articles_classification_thesis/Python/classification_pipeline\"\nif PIPELINE_DIR not in sys.path:\n    sys.path.insert(0, PIPELINE_DIR)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SPLIT KONFIGURATION =====\n",
    "\n",
    "# Modus: \"percentage\" oder \"absolute\"\n",
    "SPLIT_MODE = \"percentage\"\n",
    "\n",
    "# Percentage-Modus: Anteil der Train-Daten für Eval\n",
    "EVAL_FRACTION = 0.2\n",
    "\n",
    "# Absolute-Modus: Exakte Anzahl pro Klasse für Eval (nur wenn SPLIT_MODE = \"absolute\")\n",
    "EVAL_PER_CLASS = 10\n",
    "\n",
    "# Random Seed für reproduzierbare Splits\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# ===== DATEN LADEN =====\n",
    "\n",
    "# True  = Alle Daten laden inkl. ~259k unlabeled Raw-Daten (braucht mehr RAM)\n",
    "# False = Nur gelabelte Daten laden (Train + Test) — schneller, weniger Speicher\n",
    "LOAD_RAW = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LABEL MAPPING =====\n",
    "# Links:  Original-Label im Datensatz\n",
    "# Rechts: Neuer Name (Default = gleich wie Original)\n",
    "#\n",
    "# Beispiel: Um \"Ukraine/Krieg/Russland\" umzubenennen:\n",
    "#   \"Ukraine/Krieg/Russland\": \"Ukraine-Krieg\",\n",
    "\n",
    "LABEL_MAPPING = {\n",
    "    \"Klima / Energie\": \"Klima / Energie\",\n",
    "    \"Zuwanderung\": \"Zuwanderung\",\n",
    "    \"Renten\": \"Renten\",\n",
    "    \"Soziales Gefälle\": \"Soziales Gefälle\",\n",
    "    \"AfD/Rechte\": \"AfD/Rechte\",\n",
    "    \"Arbeitslosigkeit\": \"Arbeitslosigkeit\",\n",
    "    \"Wirtschaftslage\": \"Wirtschaftslage\",\n",
    "    \"Politikverdruss\": \"Politikverdruss\",\n",
    "    \"Gesundheitswesen, Pflege\": \"Gesundheitswesen, Pflege\",\n",
    "    \"Kosten/Löhne/Preise\": \"Kosten/Löhne/Preise\",\n",
    "    \"Ukraine/Krieg/Russland\": \"Ukraine/Krieg/Russland\",\n",
    "    \"Bundeswehr/Verteidigung\": \"Bundeswehr/Verteidigung\",\n",
    "    \"Andere\": \"Andere\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace Auth\n",
    "from huggingface_hub import login\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    hf_token = userdata.get(\"HF_TOKEN\")\n",
    "except Exception:\n",
    "    hf_token = input(\"HuggingFace Token eingeben: \")\n",
    "\n",
    "login(token=hf_token)\n",
    "print(\"HuggingFace authentifiziert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset von HuggingFace laden\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "DATASET_ID = \"Zorryy/news_articles_2025_elections_germany\"\n",
    "\n",
    "ds = load_dataset(DATASET_ID, token=hf_token)\n",
    "\n",
    "test_df = ds[\"test\"].to_pandas()\n",
    "train_full_df = ds[\"train\"].to_pandas()\n",
    "\n",
    "if LOAD_RAW:\n",
    "    raw_df = ds[\"raw\"].to_pandas()\n",
    "    print(f\"Raw:   {len(raw_df):>7} Artikel (unlabeled) geladen\")\n",
    "else:\n",
    "    raw_df = None\n",
    "    print(\"Raw-Daten nicht geladen (LOAD_RAW = False)\")\n",
    "\n",
    "print(f\"Test:  {len(test_df):>7} Artikel (FROZEN)\")\n",
    "print(f\"Train: {len(train_full_df):>7} Artikel (wird in Train + Eval aufgeteilt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-Mapping anwenden\n",
    "def apply_label_mapping(df, mapping):\n",
    "    \"\"\"Benennt Labels gemäß Mapping um.\"\"\"\n",
    "    if \"label\" not in df.columns:\n",
    "        return df\n",
    "    original_labels = set(df[\"label\"].unique())\n",
    "    mapping_keys = set(mapping.keys())\n",
    "    missing = original_labels - mapping_keys\n",
    "    if missing:\n",
    "        print(f\"  WARNUNG: Labels im Datensatz ohne Mapping: {missing}\")\n",
    "    df = df.copy()\n",
    "    df[\"label\"] = df[\"label\"].map(mapping).fillna(df[\"label\"])\n",
    "    return df\n",
    "\n",
    "test_df = apply_label_mapping(test_df, LABEL_MAPPING)\n",
    "train_full_df = apply_label_mapping(train_full_df, LABEL_MAPPING)\n",
    "if raw_df is not None and \"label\" in raw_df.columns:\n",
    "    raw_df = apply_label_mapping(raw_df, LABEL_MAPPING)\n",
    "\n",
    "# Zeige Mapping-Änderungen\n",
    "remapped = {k: v for k, v in LABEL_MAPPING.items() if k != v}\n",
    "if remapped:\n",
    "    print(\"Label-Mapping Änderungen:\")\n",
    "    for orig, new in remapped.items():\n",
    "        print(f\"  {orig} → {new}\")\n",
    "else:\n",
    "    print(\"Keine Labels umbenannt (alle Defaults).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train/Eval Split\nfrom sklearn.model_selection import train_test_split\n\nif SPLIT_MODE == \"percentage\":\n    # Klassen mit <2 Artikeln können nicht stratified gesplittet werden\n    # Diese gehen komplett in Train\n    class_counts = train_full_df[\"label\"].value_counts()\n    small_classes = class_counts[class_counts < 2].index.tolist()\n\n    if small_classes:\n        print(f\"Klassen mit <2 Artikeln (gehen komplett in Train): {small_classes}\")\n        mask_small = train_full_df[\"label\"].isin(small_classes)\n        splittable_df = train_full_df[~mask_small]\n        small_df = train_full_df[mask_small]\n\n        train_df, eval_df = train_test_split(\n            splittable_df,\n            test_size=EVAL_FRACTION,\n            stratify=splittable_df[\"label\"],\n            random_state=RANDOM_SEED,\n        )\n        train_df = pd.concat([train_df, small_df])\n    else:\n        train_df, eval_df = train_test_split(\n            train_full_df,\n            test_size=EVAL_FRACTION,\n            stratify=train_full_df[\"label\"],\n            random_state=RANDOM_SEED,\n        )\nelif SPLIT_MODE == \"absolute\":\n    eval_parts = []\n    train_parts = []\n    for label in train_full_df[\"label\"].unique():\n        class_df = train_full_df[train_full_df[\"label\"] == label]\n        n = min(len(class_df), EVAL_PER_CLASS)\n        if n < 2:\n            print(f\"  {label}: nur {len(class_df)} Artikel -> komplett in Train\")\n            train_parts.append(class_df)\n            continue\n        eval_sample = class_df.sample(n=n, random_state=RANDOM_SEED)\n        eval_parts.append(eval_sample)\n        train_parts.append(class_df.drop(eval_sample.index))\n    eval_df = pd.concat(eval_parts).reset_index(drop=True)\n    train_df = pd.concat(train_parts).reset_index(drop=True)\nelse:\n    raise ValueError(f\"Ungültiger SPLIT_MODE: {SPLIT_MODE}. Nutze 'percentage' oder 'absolute'.\")\n\ntrain_df = train_df.reset_index(drop=True)\neval_df = eval_df.reset_index(drop=True)\n\nprint(f\"\\nTrain: {len(train_df):>6} Artikel\")\nprint(f\"Eval:  {len(eval_df):>6} Artikel\")\nprint(f\"Test:  {len(test_df):>6} Artikel (FROZEN)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Runtime speichern\n",
    "import importlib\n",
    "import pipeline_utils as pu\n",
    "importlib.reload(pu)\n",
    "\n",
    "split_config = {\n",
    "    \"dataset_id\": DATASET_ID,\n",
    "    \"split_mode\": SPLIT_MODE,\n",
    "    \"eval_fraction\": EVAL_FRACTION if SPLIT_MODE == \"percentage\" else None,\n",
    "    \"eval_per_class\": EVAL_PER_CLASS if SPLIT_MODE == \"absolute\" else None,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"load_raw\": LOAD_RAW,\n",
    "    \"train_size\": len(train_df),\n",
    "    \"eval_size\": len(eval_df),\n",
    "    \"test_size\": len(test_df),\n",
    "    \"raw_size\": len(raw_df) if raw_df is not None else 0,\n",
    "}\n",
    "\n",
    "pu.set_runtime_data(train_df, eval_df, test_df, raw_df, split_config, LABEL_MAPPING)\n",
    "\n",
    "print(\"\\nDaten im Runtime-Cache gespeichert.\")\n",
    "print(\"Verfügbar via: pipeline_utils.get_runtime_data()\")\n",
    "\n",
    "# Verteilung pro Klasse\n",
    "for name, split_df in [(\"Train\", train_df), (\"Eval\", eval_df), (\"Test\", test_df)]:\n",
    "    print(f\"\\n{name} Verteilung ({len(split_df)} Artikel):\")\n",
    "    print(split_df[\"label\"].value_counts().to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}